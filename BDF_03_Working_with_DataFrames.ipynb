{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaulSerin/Big-Data-Framework/blob/main/BDF_03_Working_with_DataFrames.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-h_wDcNlH_K"
      },
      "source": [
        "#00 - Configuration of Apache Spark on Collaboratory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvD4HBMi0ohY"
      },
      "source": [
        "###Installing Java, Spark, and Findspark\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This code installs Apache Spark 2.4.4, Java 8, and [Findspark](https://github.com/minrk/findspark), a library that makes it easy for Python to find Spark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KsAfQ0CrgnWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9035b61-c1d8-4214-f0dd-ccf5b2d1de10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,172 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,501 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,616 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,323 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,452 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,223 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,734 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,512 kB]\n",
            "Fetched 23.9 MB in 11s (2,249 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "--2024-11-25 13:21:25--  http://apache.osuosl.org/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz\n",
            "Resolving apache.osuosl.org (apache.osuosl.org)... 64.50.233.100, 140.211.166.134, 64.50.236.52, ...\n",
            "Connecting to apache.osuosl.org (apache.osuosl.org)|64.50.233.100|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 400864419 (382M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.5.3-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.5.3-bin-had 100%[===================>] 382.29M  56.9MB/s    in 54s     \n",
            "\n",
            "2024-11-25 13:22:19 (7.02 MB/s) - ‘spark-3.5.3-bin-hadoop3.tgz’ saved [400864419/400864419]\n",
            "\n",
            "spark-3.5.3-bin-hadoop3.tgz\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"SPARK_VERSION\"] = \"spark-3.5.3\"\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget  http://apache.osuosl.org/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n",
        "!echo $SPARK_VERSION-bin-hadoop3.tgz\n",
        "!rm $SPARK_VERSION-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4Kjvk_h1AHl"
      },
      "source": [
        "### Set Environment Variables\n",
        "Set the locations where Spark and Java are installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hiOoj3rUgnVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a14997-8d59-40e9-e63f-ce8a99d8c648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/spark': No such file or directory\n",
            "/content/spark/\n",
            "DRIVE_DATA=/content/gdrive/My Drive/Big Data Framework/data/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark/\"\n",
        "os.environ[\"DRIVE_DATA\"] = \"/content/gdrive/My Drive/Big Data Framework/data/\"\n",
        "\n",
        "!rm /content/spark\n",
        "!ln -s /content/$SPARK_VERSION-bin-hadoop3 /content/spark\n",
        "!export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin\n",
        "!echo $SPARK_HOME\n",
        "!env |grep  \"DRIVE_DATA\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwU28K5f1H3P"
      },
      "source": [
        "### Start a SparkSession\n",
        "This will start a local Spark session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "n-4asPkCgnVB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74f6ed11-b200-42d5-9a1a-d761cecc979c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "PySpark version 3.5.3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "!python -V\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "# Example: shows the PySpark version\n",
        "print(\"PySpark version {0}\".format(sc.version))\n",
        "\n",
        "# Example: parallelise an array and show the 2 first elements\n",
        "sc.parallelize([2, 3, 4, 5, 6]).cache().take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pth1GUUrgnUW"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "# We create a SparkSession object (or we retrieve it if it is already created)\n",
        "spark = SparkSession \\\n",
        ".builder \\\n",
        ".appName(\"My application\") \\\n",
        ".config(\"spark.some.config.option\", \"some-value\") \\\n",
        ".master(\"local[4]\") \\\n",
        ".getOrCreate()\n",
        "# We get the SparkContext\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9tfoycrngnSJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c0d4d0e-a2a0-4850-ce8c-e0b30ba6fece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkKGBZRvEwZL"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# 03 - Working with DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcr9KTJbJI_4"
      },
      "source": [
        "## Introduction to DataFrames\n",
        "We will see:\n",
        "\n",
        "  - How to create a DataFrame\n",
        "  - Basic operations on DataFrames\n",
        "      - Show rows\n",
        "      - Select columns\n",
        "      - Rename, add and delete columns\n",
        "      - Delete null values and duplicated rows\n",
        "      - Replace values\n",
        "  - Save DataFrames in different formats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu6TkZeNd5hz"
      },
      "source": [
        "## Creating DataFrames\n",
        "A DataFrame can be created in different ways:\n",
        "\n",
        "  - From a data sequence\n",
        "  - From Row-type objects\n",
        "  - From an RDD or a DataSet\n",
        "  - Reading data from a file\n",
        "      - Like in Hadoop, Spark supports different filesystems: local, HDFS, Amazon S3\n",
        "          - By and large, it supports any data source that can be read with Hadoop\n",
        "      - Spark can access different types of files: plain text, CSV, JSON, [Parquet](https://parquet.apache.org/), [ORC](https://orc.apache.org/), Sequence, etc\n",
        "        -   It also supports compressed files\n",
        "  - Accessing relational databases or noSQL databases\n",
        "    -   MySQL, Postgres, etc. using JDBC/ODBC\n",
        "    -  Hive, HBase, Cassandra, MongoDB, AWS Redshift, etc.\n",
        "    \n",
        "Some examples on how to create DataFrames below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDJ4UH8wfoO7"
      },
      "source": [
        "### From a sequence or a list of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uCnbq2bgf5Rd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0298562-9306-42ad-d7fc-19aba5abf840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "|  n|\n",
            "+---+\n",
            "|  1|\n",
            "|  3|\n",
            "|  5|\n",
            "+---+\n",
            "\n",
            "+---+---+---+\n",
            "|  n| n1| n2|\n",
            "+---+---+---+\n",
            "|  1|  2|  2|\n",
            "|  3|  4|  6|\n",
            "|  5|  6| 10|\n",
            "+---+---+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col,expr\n",
        "# Creating a DataFrame from a range and adding two columns\n",
        "df = spark.range(1,7,2).toDF(\"n\")\n",
        "df.show()\n",
        "df.withColumn(\"n1\", col(\"n\")+1).withColumn(\"n2\", expr(\"2*n\")).show()\n",
        "# Note that in the call to 'expr' we can include SQL code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JxcY86E-f9Ub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99a388ce-8a91-4659-a188-f848bb8dcfd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+------+\n",
            "|  Name|mark|result|\n",
            "+------+----+------+\n",
            "|  Eric| 5.1|  Pass|\n",
            "|  John| 4.0|  Fail|\n",
            "|Manuel|NULL|  NULL|\n",
            "+------+----+------+\n",
            "\n",
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- mark: double (nullable = true)\n",
            " |-- result: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# DataFrame from a list of tuples\n",
        "l = [(\"Eric\", 5.1, \"Pass\"),\\\n",
        "     (\"John\", 4.0, \"Fail\"),\\\n",
        "     (\"Manuel\", None, None)]\n",
        "dfMarks = spark.createDataFrame(l, schema=[\"Name\", \"mark\", \"result\"])\n",
        "dfMarks.show()\n",
        "dfMarks.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH7LS_dYgCmH"
      },
      "source": [
        "### Creating DataFrames with a schema\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g88zsnXygSlG"
      },
      "source": [
        "When creating a DataFrame, it is a good idea to specify its schema:\n",
        "\n",
        "  - The schema defines the names and data types of each column\n",
        "  - It uses an object of type ``StructType`` to define the name and type of the columns\n",
        "  - The data types used by Spark are defined in:\n",
        "      - For PySpark: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#data-types\n",
        "      - For Scala: https://spark.apache.org/docs/latest/api/scala/#org.apache.spark.sql.types.package\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uStMKrWmgcfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33bfc23f-53fa-46a1-e5fd-44581b2b09be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+------+\n",
            "|  Name|mark|result|\n",
            "+------+----+------+\n",
            "|  Eric| 5.1|  Pass|\n",
            "|  John| 4.0|  Fail|\n",
            "|Manuel|NULL|  NULL|\n",
            "+------+----+------+\n",
            "\n",
            "root\n",
            " |-- Name: string (nullable = false)\n",
            " |-- mark: float (nullable = true)\n",
            " |-- result: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.types import StructField, StructType, FloatType, StringType\n",
        "from pyspark.sql import Row\n",
        "# Define the DataFrame schema\n",
        "schemaMarks = StructType([\n",
        "    StructField(\"Name\", StringType(), False),\n",
        "    StructField(\"mark\", FloatType(), True),\n",
        "    StructField(\"result\", StringType(), True)\n",
        "    ])\n",
        "\n",
        "# Create the DataFrame from a list of Row objects\n",
        "rows = [Row(\"Eric\", 5.1, \"Pass\"),\\\n",
        "         Row(\"John\", 4.0, \"Fail\"),\\\n",
        "         Row(\"Manuel\", None, None)]\n",
        "\n",
        "dfMarks = spark.createDataFrame(rows, schema=schemaMarks)\n",
        "dfMarks.show()\n",
        "dfMarks.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-C7Wg96gd5s"
      },
      "source": [
        "### Creating DataFrames from a text file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9bRWavNgk0U"
      },
      "source": [
        "Each file line is stored as a row"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbijvVbcgtw3"
      },
      "source": [
        "### Creating DataFrames from a CSV file (revisited)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDIe3EAEg4xo"
      },
      "source": [
        "As an example, we are going to use a file with questions and replies from Stack Exchange (https://stackexchange.com/) in Italian.\n",
        "It is a CVS file, with the following 13 fields:\n",
        "\n",
        "  0. ``nComs`` - Number of comments of the question of the reply\n",
        "  2. ``lastActivity`` - Date and hour of the last modification\n",
        "  3. ``userId`` - Owner's ID\n",
        "  4. ``body`` - Text of the question or reply\n",
        "  5. ``score`` - Score of the question or reply based on positive and negative votes\n",
        "  6. ``creationDate`` - Creation date and hour\n",
        "  6. ``numViewed`` - Number of times viewed (null if the question has never been viewed)\n",
        "  7. ``title`` - Question title (null if it is a reply)\n",
        "  8. ``tags`` - Tags assigned to the question (null if there are no tags assigned)\n",
        "  9. ``nAnswers`` - Number of replies related to the question (null if there are not any)\n",
        "  10. ``acceptedAnswerId`` - The ID of the accepted answer (null if the question has no accepted answer)\n",
        "  11. ``postType`` - Type of message: 1 question, 2 reply\n",
        "  12. ``id`` - Unique message identifier\n",
        "\n",
        "Fields are separated by the \"~\" symbol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H07ygUKhL0p"
      },
      "source": [
        "#### a) Read the file and infer the schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "V2Lzn1GMhXxz"
      },
      "outputs": [],
      "source": [
        "dfSEInferred = spark.read.format(\"csv\")\\\n",
        "                    .option(\"mode\", \"FAILFAST\")\\\n",
        "                    .option(\"sep\", \"~\")\\\n",
        "                    .option(\"inferSchema\", \"true\")\\\n",
        "                    .option(\"header\", \"false\")\\\n",
        "                    .option(\"nullValue\", \"null\")\\\n",
        "                    .option(\"compression\", \"bzip2\")\\\n",
        "                    .load(os.environ[\"DRIVE_DATA\"] +\"italianPosts.csv.bz2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTjGjjNNhYUf"
      },
      "source": [
        "Some options:\n",
        "\n",
        "1. ``mode``: specifies what to do when it finds corrupted entries\n",
        "    - ``PERMISSIVE``: sets all fields to null when a corrupted entry is found (default value)\n",
        "    - ``DROPMALFORMED``: deletes the rows with corrupted entries\n",
        "    - ``FAILFAST``: returns an error when a corrupted entry is found\n",
        "2. ``sep``:  field delimiter (by default \",\")\n",
        "3. ``inferSchema``: whether column types must be inferred (by default \"false\")\n",
        "4. ``header``: if \"true\", the first line is taken as the header (by default \"false\")\n",
        "5. ``nullValue``: character or string thar represents a NULL in the file  (by default \"\")\n",
        "6. ``compression``: compression type (by default \"none\")\n",
        "  \n",
        "These options are similar for other types of files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "V1atd4MqhghB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78053025-1b07-4b03-9c31-cf63ea0c0951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+---+--------------------+---+--------------------+----+--------------------+--------------------+----+----+----+----+\n",
            "|_c0|                 _c1|_c2|                 _c3|_c4|                 _c5| _c6|                 _c7|                 _c8| _c9|_c10|_c11|_c12|\n",
            "+---+--------------------+---+--------------------+---+--------------------+----+--------------------+--------------------+----+----+----+----+\n",
            "|  4|2013-11-11 18:21:...| 17|&lt;p&gt;The infi...| 23|2013-11-10 19:37:...|NULL|                NULL|                NULL|NULL|NULL|   2|1165|\n",
            "|  5|2013-11-10 20:31:...| 12|&lt;p&gt;Come cre...|  1|2013-11-10 19:44:...|  61|Cosa sapreste dir...| &lt;word-choice&gt;|   1|NULL|   1|1166|\n",
            "|  2|2013-11-10 20:31:...| 17|&lt;p&gt;Il verbo...|  5|2013-11-10 19:58:...|NULL|                NULL|                NULL|NULL|NULL|   2|1167|\n",
            "|  1|2014-07-25 13:15:...|154|&lt;p&gt;As part ...| 11|2013-11-10 22:03:...| 187|Ironic constructi...|&lt;english-compa...|   4|1170|   1|1168|\n",
            "|  0|2013-11-10 22:15:...| 70|&lt;p&gt;&lt;em&g...|  3|2013-11-10 22:15:...|NULL|                NULL|                NULL|NULL|NULL|   2|1169|\n",
            "+---+--------------------+---+--------------------+---+--------------------+----+--------------------+--------------------+----+----+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show 5 rows\n",
        "dfSEInferred.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LjM7KCurhkRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c579ebd-3daa-4b62-8e98-c3dcb7cb8134"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType([StructField('_c0', IntegerType(), True), StructField('_c1', TimestampType(), True), StructField('_c2', IntegerType(), True), StructField('_c3', StringType(), True), StructField('_c4', IntegerType(), True), StructField('_c5', TimestampType(), True), StructField('_c6', IntegerType(), True), StructField('_c7', StringType(), True), StructField('_c8', StringType(), True), StructField('_c9', IntegerType(), True), StructField('_c10', IntegerType(), True), StructField('_c11', IntegerType(), True), StructField('_c12', IntegerType(), True)])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Find out how the schema was inferred\n",
        "dfSEInferred.schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "r4Q9AQ4dhn5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7512a79-f9df-410a-fa7b-5cf64c0e5d98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- _c1: timestamp (nullable = true)\n",
            " |-- _c2: integer (nullable = true)\n",
            " |-- _c3: string (nullable = true)\n",
            " |-- _c4: integer (nullable = true)\n",
            " |-- _c5: timestamp (nullable = true)\n",
            " |-- _c6: integer (nullable = true)\n",
            " |-- _c7: string (nullable = true)\n",
            " |-- _c8: string (nullable = true)\n",
            " |-- _c9: integer (nullable = true)\n",
            " |-- _c10: integer (nullable = true)\n",
            " |-- _c11: integer (nullable = true)\n",
            " |-- _c12: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Another way of getting the same result\n",
        "dfSEInferred.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbK_qvf3hs5v"
      },
      "source": [
        "#### b) Read the file and specify the schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "g1xnLchfhzD6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "714f76a3-1b3c-435d-b463-02e7a576aec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|nComs|        lastActivity|userId|                body|score|        creationDate|numViewed|               title|                tags|nAnswers|acceptedAnswerId|postType|  id|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|    4|2013-11-11 18:21:...|    17|&lt;p&gt;The infi...|   23|2013-11-10 19:37:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1165|\n",
            "|    5|2013-11-10 20:31:...|    12|&lt;p&gt;Come cre...|    1|2013-11-10 19:44:...|       61|Cosa sapreste dir...| &lt;word-choice&gt;|       1|            NULL|       1|1166|\n",
            "|    2|2013-11-10 20:31:...|    17|&lt;p&gt;Il verbo...|    5|2013-11-10 19:58:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1167|\n",
            "|    1|2014-07-25 13:15:...|   154|&lt;p&gt;As part ...|   11|2013-11-10 22:03:...|      187|Ironic constructi...|&lt;english-compa...|       4|            1170|       1|1168|\n",
            "|    0|2013-11-10 22:15:...|    70|&lt;p&gt;&lt;em&g...|    3|2013-11-10 22:15:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1169|\n",
            "|    2|2013-11-10 22:17:...|    17|&lt;p&gt;There's ...|    8|2013-11-10 22:17:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1170|\n",
            "|    1|2013-11-11 09:51:...|    63|&lt;p&gt;As other...|    3|2013-11-11 09:51:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1171|\n",
            "|    1|2013-11-12 23:57:...|    63|&lt;p&gt;The expr...|    1|2013-11-11 10:09:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1172|\n",
            "|    9|2014-01-05 11:13:...|    63|&lt;p&gt;When I w...|    5|2013-11-11 10:28:...|      122|Is &quot;scancell...|&lt;usage&gt;&lt;...|       3|            1181|       1|1173|\n",
            "|    0|2013-11-11 10:58:...|    18|&lt;p&gt;Wow, wha...|    5|2013-11-11 10:58:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1174|\n",
            "|    1|2014-01-16 19:56:...|    63|&lt;p&gt;Suppose ...|    4|2013-11-11 11:31:...|      114|How should I tran...|&lt;usage&gt;&lt;...|       2|            1177|       1|1175|\n",
            "|    0|2013-11-11 14:36:...|    63|&lt;p&gt;Except w...|    3|2013-11-11 11:39:...|       58|Using a comma bet...|&lt;usage&gt;&lt;...|       2|            1182|       1|1176|\n",
            "|    3|2014-01-16 19:56:...|    71|&lt;p&gt;Both you...|    6|2013-11-11 11:57:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1177|\n",
            "|    0|2013-11-11 12:00:...|    12|&lt;blockquote&gt...|    1|2013-11-11 12:00:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1178|\n",
            "|    0|2013-11-12 11:24:...|    63|&lt;p&gt;Comparin...|    3|2013-11-11 12:58:...|       60|Using the conditi...|&lt;usage&gt;&lt;...|       2|            1180|       1|1179|\n",
            "|    4|2013-11-11 19:54:...|    18|&lt;p&gt;Using th...|    5|2013-11-11 13:48:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1180|\n",
            "|    0|2013-11-11 18:20:...|   132|&lt;p&gt;I would ...|    8|2013-11-11 14:04:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1181|\n",
            "|    1|2013-11-11 14:36:...|   132|&lt;p&gt;Putting ...|   11|2013-11-11 14:17:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1182|\n",
            "|    2|2013-11-14 09:56:...|    22|&lt;p&gt;Many peo...|    6|2013-11-11 14:43:...|      321|Can Dante Alighie...|&lt;history&gt;&l...|       1|            1263|       1|1183|\n",
            "|    2|2013-11-11 23:23:...|   159|&lt;p&gt;Sono un'...|    7|2013-11-11 18:19:...|      138|origine dell'espr...|&lt;idioms&gt;&lt...|       2|            1185|       1|1184|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.types import *\n",
        "# We first create a list with each column header\n",
        "# Note: avoid spaces and non-ascii characters on column names\n",
        "header = ([\"nComs\", \"lastActivity\", \"userId\",\n",
        "            \"body\", \"score\", \"creationDate\", \"numViewed\", \"title\",\n",
        "            \"tags\", \"nAnswers\", \"acceptedAnswerId\", \"postType\", \"id\"])\n",
        "\n",
        "# Define the schema for the elements of the table\n",
        "# StructType -> Defines a schema for the DF from a list of StructFields\n",
        "# StructField -> Defines the name and type of each column, and whether it is nullable or not (True field)\n",
        "dfSE_Schema = StructType([\n",
        "  StructField(header[0], IntegerType(), True),\n",
        "  StructField(header[1], TimestampType(), True),\n",
        "  StructField(header[2], LongType(), True),\n",
        "  StructField(header[3], StringType(), True),\n",
        "  StructField(header[4], IntegerType(), True),\n",
        "  StructField(header[5], TimestampType(), True),\n",
        "  StructField(header[6], IntegerType(), True),\n",
        "  StructField(header[7], StringType(), True),\n",
        "  StructField(header[8], StringType(), True),\n",
        "  StructField(header[9], IntegerType(), True),\n",
        "  StructField(header[10], LongType(), True),\n",
        "  StructField(header[11], ByteType(), True),\n",
        "  StructField(header[12], LongType(), True)\n",
        "  ])\n",
        "\n",
        "dfSE = spark.read.format(\"csv\")\\\n",
        "                    .option(\"mode\", \"FAILFAST\")\\\n",
        "                    .option(\"sep\", \"~\")\\\n",
        "                    .option(\"inferSchema\", \"false\")\\\n",
        "                    .option(\"header\", \"false\")\\\n",
        "                    .option(\"nullValue\", \"null\")\\\n",
        "                    .option(\"compression\", \"bzip2\")\\\n",
        "                    .schema(dfSE_Schema)\\\n",
        "                    .load(os.environ[\"DRIVE_DATA\"] +\"italianPosts.csv.bz2\")\n",
        "dfSE.cache()\n",
        "dfSE.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwS3ZIcFh3y2"
      },
      "outputs": [],
      "source": [
        "dfSE.sort(\"id\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Y1wlNqCsh4Wv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acfab840-9302-4e49-af01-dbc6f6c9519d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- nComs: integer (nullable = true)\n",
            " |-- lastActivity: timestamp (nullable = true)\n",
            " |-- userId: long (nullable = true)\n",
            " |-- body: string (nullable = true)\n",
            " |-- score: integer (nullable = true)\n",
            " |-- creationDate: timestamp (nullable = true)\n",
            " |-- numViewed: integer (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- tags: string (nullable = true)\n",
            " |-- nAnswers: integer (nullable = true)\n",
            " |-- acceptedAnswerId: long (nullable = true)\n",
            " |-- postType: byte (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dfSE.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7JqL8PojOEa"
      },
      "source": [
        "## Basic operations with DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx69XYmUjUP7"
      },
      "source": [
        "### Show rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oRtkoWUZjaHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ebe1888-36b3-475b-875f-30da6e00e452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|nComs|        lastActivity|userId|                body|score|        creationDate|numViewed|               title|                tags|nAnswers|acceptedAnswerId|postType|  id|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|    4|2013-11-11 18:21:...|    17|&lt;p&gt;The infi...|   23|2013-11-10 19:37:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1165|\n",
            "|    5|2013-11-10 20:31:...|    12|&lt;p&gt;Come cre...|    1|2013-11-10 19:44:...|       61|Cosa sapreste dir...| &lt;word-choice&gt;|       1|            NULL|       1|1166|\n",
            "|    2|2013-11-10 20:31:...|    17|&lt;p&gt;Il verbo...|    5|2013-11-10 19:58:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1167|\n",
            "|    1|2014-07-25 13:15:...|   154|&lt;p&gt;As part ...|   11|2013-11-10 22:03:...|      187|Ironic constructi...|&lt;english-compa...|       4|            1170|       1|1168|\n",
            "|    0|2013-11-10 22:15:...|    70|&lt;p&gt;&lt;em&g...|    3|2013-11-10 22:15:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1169|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# show(n) shows the first n rows (by default, n=20)\n",
        "dfSE.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "b4Nyk4RrjePd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f3d39f6-6b33-45a0-c8c2-5f212899cf2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------------+------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-----------------------+---------+------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------+--------+----------------+--------+----+\n",
            "|nComs|lastActivity           |userId|body                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |score|creationDate           |numViewed|title                                                                                                 |tags                                                               |nAnswers|acceptedAnswerId|postType|id  |\n",
            "+-----+-----------------------+------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-----------------------+---------+------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------+--------+----------------+--------+----+\n",
            "|4    |2013-11-11 18:21:10.903|17    |&lt;p&gt;The infinitive tense is commonly used for expressing rules especially in signs (of any kind, not just road signs).&lt;/p&gt;&lt;p&gt;For instance&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Non fumare&lt;br&gt;  Non calpestare il prato&lt;br&gt;  Tenere la destra&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;The language &quot;trick&quot; behind this use of the infinitive form is the omission of the clause &lt;em&gt;Si prega di&lt;/em&gt; or equivalent, so the above sentences are read as&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;&lt;em&gt;&lt;strong&gt;Si prega di&lt;/em&gt;&lt;/strong&gt; non fumare&lt;br&gt;  &lt;strong&gt;&lt;em&gt;Si prega di&lt;/em&gt;&lt;/strong&gt; non calpestare il prato&lt;br&gt;  &lt;strong&gt;&lt;em&gt;Si prega di&lt;/em&gt;&lt;/strong&gt; tenere la destra&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Such form is not used in everyday's spoken language, as it's a convention used for giving orders and stating rules in an impersonal and formal way.&lt;/p&gt;&lt;hr&gt;&lt;p&gt;That being said, there's an official use of the infinitive tense as imperative, which is the negative imperative.&lt;/p&gt;&lt;p&gt;In Italian the positive imperative form goes as follows&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Tieni la destra!&lt;br&gt;  Parla con lei!&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;whereas the negative imperative is formed with &lt;strong&gt;&lt;em&gt;non + infinitive tense&lt;/em&gt;&lt;/strong&gt;, as in &lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Non tenere la destra!&lt;br&gt;  Non parlare con lei!&lt;/p&gt;&lt;/blockquote&gt;&lt;hr&gt;&lt;p&gt;As discussed in the comments, it's also nice to notice the differences and the similarities with other Romance languages, such as Spanish and French.&lt;/p&gt;&lt;p&gt;Apparently French has the same identical construct as Italian for expressing formal impersonal orders, for instance&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Ne pas fumer&lt;br&gt;  &lt;em&gt;Non fumare&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;which is again a shortening for&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Merci de ne pas fumer&lt;br&gt;  &lt;em&gt;Grazie di non fumare&lt;/em&gt; or more idiomatically &lt;em&gt;Si prega di non fumare&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;On the other hand Spanish behaves differently and it doesn't have a special construct for impersonal orders, rather just using the formal imperative form, which is formed with the subjunctive&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;No fume&lt;br&gt;  &lt;em&gt;Non fumare&lt;/em&gt;, but also &lt;em&gt;Non fumi&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;or&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Reduzca la velocidad&lt;br&gt;  &lt;em&gt;Ridurre la velocità&lt;/em&gt;, but also &lt;em&gt;Riduca la velocità&lt;/em&gt;&lt;/p&gt;&lt;/blockquote&gt;|23   |2013-11-10 19:37:54.187|NULL     |NULL                                                                                                  |NULL                                                               |NULL    |NULL            |2       |1165|\n",
            "|5    |2013-11-10 20:31:00.177|12    |&lt;p&gt;Come credo sia conosciuto da tutti quelli che usano viaggiare con l'automobile, molti italiani hanno uno strano rapporto con gli abbaglianti; alcuni li amano così tanto che preferiscono mantenerli sempre accesi, altri invece li usano per segnalare, se non addirittura per comunicare informazioni di vario genere, dalla presenza di autovelox alla protesta per presunte violazioni del codice della strada.&lt;/p&gt;&lt;p&gt;Al di lá delle considerazioni e dei commenti circa queste abitudini, mi piacerebbe sapere se il verbo &quot;sfanagliare&quot; è normalmente usato, e compreso, in tutte le regioni italiane o se, magari, ci sono altri verbi in uso, purchè simpatici come quello.&lt;/p&gt;&lt;p&gt;Laddove qualcuno non avesse compreso l'uso del aforementioned verbo, ecco un esempio:&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;&quot;Ehi!&quot; - dice il marito a sua moglie - &quot;Quello li mi sta sfanagliando, st***o!&quot;&lt;/p&gt;    &lt;p&gt;E la moglie, &quot;Caro, rallenta; magari più avanti c'è un autovelox, cribbio!&quot;&lt;/p&gt;&lt;/blockquote&gt;                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |1    |2013-11-10 19:44:53.797|61       |Cosa sapreste dirmi della diffusione del verbo &quot;sfanagliare&quot; nelle diverse regioni italiane?|&lt;word-choice&gt;                                                |1       |NULL            |1       |1166|\n",
            "|2    |2013-11-10 20:31:00.177|17    |&lt;p&gt;Il verbo &lt;strong&gt;&lt;em&gt;sfanagliare&lt;/em&gt;&lt;/strong&gt; è un verbo inventato, non esistente nella lingua italiana, ma questo penso fosse chiaro dalla domanda.&lt;/p&gt;&lt;p&gt;Personalmente non l'ho mai sentito usare nel nord Italia, quindi non credo abbia una diffusione regionale omogenea. Un'alternativa che mi è capitato invece di sentire  è &lt;strong&gt;&lt;em&gt;sfanalare&lt;/em&gt;&lt;/strong&gt;, con significato identico.&lt;/p&gt;&lt;p&gt;Ad ogni modo, non sono sicuro dell'interpretazione di &lt;strong&gt;&lt;em&gt;sfanalare&lt;/em&gt;&lt;/strong&gt;/&lt;em&gt;&lt;strong&gt;sfanagliare&lt;/em&gt;&lt;/strong&gt; con il significato di &lt;strong&gt;&lt;em&gt;accecare con gli abbaglianti&lt;/em&gt;&lt;/strong&gt;. Probabilmente il significato che gli attribuirei è lo stesso di &lt;strong&gt;&lt;em&gt;fare i fari&lt;/em&gt;&lt;/strong&gt;, ossia &lt;strong&gt;&lt;em&gt;segnalare qualcosa tramite i fari abbaglianti&lt;/em&gt;&lt;/strong&gt;, solitamente accendendoli e spegnedoli ripetutamente. Per esempio&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Non mi ero accorto che il semaforo fosse diventato verde e il tizio dietro mi ha fatto i fari&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;(ok l'esempio è un po' tirato, sappiamo benissimo che il tizio di turno normalmente suona il clacson e tira una bestemmia...)&lt;/p&gt;&lt;p&gt;oppure&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Una vecchia consuetudine italiana era quella di sfanalare per segnalare la presenza della polizia stradale&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Nell'esempio che hai menzionato userei invece qualcosa del tipo&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Quello lì mi sta abbagliando (con sti c***o di fari, &lt;em&gt;ndt&lt;/em&gt;), st***o!&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;or&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Quello lì mi sta accecando (con sti c***o di fari, &lt;em&gt;ndt&lt;/em&gt;), st***o!&lt;/p&gt;&lt;/blockquote&gt;                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |5    |2013-11-10 19:58:02.1  |NULL     |NULL                                                                                                  |NULL                                                               |NULL    |NULL            |2       |1167|\n",
            "|1    |2014-07-25 13:15:02.27 |154   |&lt;p&gt;As part of my masters in linguistics, I am taking a course on the subject of irony. We were given examples of sentences that are most likely ironic, as the English sentence &quot;he is not exceptionally smart&quot; (which has the structure &quot;he is not exceptionally X&quot;). This does not mean literally that he is smart at an exceptional level, but rather, ironically, that he is very stupid.&lt;/p&gt;&lt;p&gt;Are there similar constructions in Italian, preferably ones that involve superlative and negation?&lt;/p&gt;                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |11   |2013-11-10 22:03:41.027|187      |Ironic constructions in Italian                                                                       |&lt;english-comparison&gt;&lt;translation&gt;&lt;phrase-request&gt;|4       |1170            |1       |1168|\n",
            "|0    |2013-11-10 22:15:17.693|70    |&lt;p&gt;&lt;em&gt;Non è furbissimo&lt;/em&gt; can be used in the same sense as your example; or &lt;em&gt;non è velocissimo&lt;/em&gt; for someone who's rather slow. Maybe adding &lt;em&gt;proprio&lt;/em&gt;: &lt;em&gt;non è proprio furbissimo&lt;/em&gt;, which is more explicit in denying the smartness of the person.&lt;/p&gt;                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |3    |2013-11-10 22:15:17.693|NULL     |NULL                                                                                                  |NULL                                                               |NULL    |NULL            |2       |1169|\n",
            "+-----+-----------------------+------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-----------------------+---------+------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------+--------+----------------+--------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Say that we do not want to truncate the long fields\n",
        "dfSE.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "s1BBaaz-jgp-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a5a081c-9031-417a-bcb3-7ea82417f307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row(nComs=5, lastActivity=datetime.datetime(2013, 11, 10, 20, 31, 0, 177000), userId=12, body=\"&lt;p&gt;Come credo sia conosciuto da tutti quelli che usano viaggiare con l'automobile, molti italiani hanno uno strano rapporto con gli abbaglianti; alcuni li amano così tanto che preferiscono mantenerli sempre accesi, altri invece li usano per segnalare, se non addirittura per comunicare informazioni di vario genere, dalla presenza di autovelox alla protesta per presunte violazioni del codice della strada.&lt;/p&gt;&lt;p&gt;Al di lá delle considerazioni e dei commenti circa queste abitudini, mi piacerebbe sapere se il verbo &quot;sfanagliare&quot; è normalmente usato, e compreso, in tutte le regioni italiane o se, magari, ci sono altri verbi in uso, purchè simpatici come quello.&lt;/p&gt;&lt;p&gt;Laddove qualcuno non avesse compreso l'uso del aforementioned verbo, ecco un esempio:&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;&quot;Ehi!&quot; - dice il marito a sua moglie - &quot;Quello li mi sta sfanagliando, st***o!&quot;&lt;/p&gt;    &lt;p&gt;E la moglie, &quot;Caro, rallenta; magari più avanti c'è un autovelox, cribbio!&quot;&lt;/p&gt;&lt;/blockquote&gt;\", score=1, creationDate=datetime.datetime(2013, 11, 10, 19, 44, 53, 797000), numViewed=61, title='Cosa sapreste dirmi della diffusione del verbo &quot;sfanagliare&quot; nelle diverse regioni italiane?', tags='&lt;word-choice&gt;', nAnswers=1, acceptedAnswerId=None, postType=1, id=1166)\n",
            "\n",
            "\n",
            "Row(nComs=1, lastActivity=datetime.datetime(2014, 1, 16, 19, 56, 5, 933000), userId=63, body='&lt;p&gt;Suppose I want to translate an English sentence like &quot;I have walked in the park for a year.&quot; The first though I had was translating the sentence as follows.&lt;/p&gt;&lt;blockquote&gt;  &lt;p&gt;Ho camminato nel parco per un anno.&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;It seems correct, except for the fact that Present Perfect is used to talk about a past event that is still relevant for the present. That means the sentence I used as example would be understood as saying that I am still walking in the park. Similarly, &quot;I have gone to that store since I was a teenager.&quot; would mean I am still going to that store.&lt;br&gt;That is not the meaning of &quot;ho camminato nel parco per un anno&quot; which means I am not walking anymore in the park.&lt;/p&gt;&lt;p&gt;I thought of using the Simple Past, but I am not sure how to use it with a time reference. Apart that, &lt;em&gt;camminavo nel parco&lt;/em&gt; still means I am not anymore walking.&lt;/p&gt;&lt;p&gt;How should I translate the Present Perfect used in English?&lt;/p&gt;', score=4, creationDate=datetime.datetime(2013, 11, 11, 11, 31, 2, 343000), numViewed=114, title='How should I translate the Present Perfect used in English?', tags='&lt;usage&gt;&lt;tenses&gt;&lt;english-comparison&gt;', nAnswers=2, acceptedAnswerId=1177, postType=1, id=1175)\n"
          ]
        }
      ],
      "source": [
        "# take(n) returns the first n rows as a Python list of Row objects\n",
        "list = dfSE.take(5)\n",
        "print(list[1])\n",
        "print(\"\\n\")\n",
        "# collect() returns the DataFrame as a Python list of Row objects\n",
        "# Warning: if the DataFrame is too large, it might collapse the Driver!\n",
        "list2 = dfSE.collect()\n",
        "print(list2[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hPDx7xvIjif4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e19d99e-6fcd-4f9e-a234-8cfa385107e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Number of rows = 1261; Number of sampled rows = 117\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# sample(withReplacement, fraction, seed=None) returns a new Dataframe with a fraction of the original rows\n",
        "dfSESampled = dfSE.sample(False, 0.1, seed=None)\n",
        "print(\"Original Number of rows = {0}; Number of sampled rows = {1}\".format(dfSE.count(), dfSESampled.count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "x-DOlABOjkc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3807ff-c16f-490c-d1c6-fd9014292bd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sampled rows = 10\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|nComs|        lastActivity|userId|                body|score|        creationDate|numViewed|               title|                tags|nAnswers|acceptedAnswerId|postType|  id|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|    2|2013-11-10 20:31:...|    17|&lt;p&gt;Il verbo...|    5|2013-11-10 19:58:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1167|\n",
            "|    2|2013-11-10 22:17:...|    17|&lt;p&gt;There's ...|    8|2013-11-10 22:17:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1170|\n",
            "|    2|2013-11-11 23:23:...|   159|&lt;p&gt;Sono un'...|    7|2013-11-11 18:19:...|      138|origine dell'espr...|&lt;idioms&gt;&lt...|       2|            1185|       1|1184|\n",
            "|    1|2013-11-11 21:11:...|   132|&lt;p&gt;Although...|    5|2013-11-11 21:11:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1195|\n",
            "|    1|2013-11-12 11:06:...|    37|&lt;p&gt;A rule o...|    9|2013-11-12 11:06:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1207|\n",
            "|    0|2014-08-31 20:19:...|    12|&lt;p&gt;Giulia e...|    5|2013-11-12 12:04:...|      610|Cosa significa e ...|&lt;grammar&gt;&l...|       4|            NULL|       1|1211|\n",
            "|    1|2013-11-12 12:14:...|    19|&lt;p&gt;Immagino...|    5|2013-11-12 12:14:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1213|\n",
            "|    2|2013-11-14 11:50:...|    18|&lt;p&gt;Where do...|    5|2013-11-12 14:49:...|      123|Etymology of &quo...|&lt;idioms&gt;&lt...|       1|            1230|       1|1229|\n",
            "|    0|2013-11-22 23:59:...|    12|&lt;p&gt;Conoscet...|    4|2013-11-12 20:37:...|      101|Why is &quot;vi s...|     &lt;grammar&gt;|       2|            NULL|       1|1239|\n",
            "|    1|2013-11-15 12:17:...|    18|&lt;p&gt;Clearly ...|    7|2013-11-14 01:21:...|       68|Are &quot;mattina...|&lt;grammar&gt;&l...|       2|            NULL|       1|1262|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# limit(n) limits the number of rows calculated to n\n",
        "dfSE_10rows = dfSE.sample(False, 0.1, seed=None).limit(10)\n",
        "print(\"Number of sampled rows = {0}\".format(dfSE_10rows.count()))\n",
        "dfSE_10rows.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HXAspRdjnV-"
      },
      "source": [
        "### Execute an operation on each row\n",
        "The method `foreach` applies a function to each row\n",
        "\n",
        "- The DataFrame is not modified and no other DataFrames are created\n",
        "- `foreach` is executed in the Workers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "D3QC31oFjvjx"
      },
      "outputs": [],
      "source": [
        "def printid(f):\n",
        "    print(f[\"id\"])\n",
        "\n",
        "# In theory, this code should print all values of the 'id' column.\n",
        "# Due to the way the notebook manages tasks, it is not possible to see any output.\n",
        "# Run it on a pyspark-shell to see the output.\n",
        "dfSE_10rows.foreach(printid)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTZ2CtybjwQn"
      },
      "source": [
        "### Select columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "GQamd1S0jznG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef197ec5-f83a-4073-a251-b40d612fccb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+\n",
            "|  id|                body|\n",
            "+----+--------------------+\n",
            "|1165|&lt;p&gt;The infi...|\n",
            "|1166|&lt;p&gt;Come cre...|\n",
            "|1167|&lt;p&gt;Il verbo...|\n",
            "|1168|&lt;p&gt;As part ...|\n",
            "|1169|&lt;p&gt;&lt;em&g...|\n",
            "+----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "The idBody object is of type <class 'pyspark.sql.dataframe.DataFrame'>\n"
          ]
        }
      ],
      "source": [
        "# Creates a new DataFrame by selecting columns by name\n",
        "dfIdBody = dfSE.select(\"id\", \"body\")\n",
        "dfIdBody.show(5)\n",
        "\n",
        "print(\"The idBody object is of type {0}\".format(type(dfIdBody)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "zYlZy8j4j2sR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0996fdf-a32d-45ef-ea0b-48811103d8b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+\n",
            "|  id|                body|\n",
            "+----+--------------------+\n",
            "|1165|&lt;p&gt;The infi...|\n",
            "|1166|&lt;p&gt;Come cre...|\n",
            "|1167|&lt;p&gt;Il verbo...|\n",
            "|1168|&lt;p&gt;As part ...|\n",
            "|1169|&lt;p&gt;&lt;em&g...|\n",
            "+----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Another way of specifying the columns to select\n",
        "dfIdBody2 = dfSE.select(dfSE.id, dfSE.body)\n",
        "dfIdBody2.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "RQWu1PaXj3aD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30220882-968b-4685-c104-eacdd58261f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The colId object is of type <class 'pyspark.sql.column.Column'>\n",
            "The colCreateDate object is of type <class 'pyspark.sql.column.Column'>\n"
          ]
        }
      ],
      "source": [
        "# It is also possible to specify objects of Column type...\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "colId = col(\"id\")\n",
        "colCreateDate = col(\"creationDate\")\n",
        "print(\"The colId object is of type {0}\".format(type(colId)))\n",
        "print(\"The colCreateDate object is of type {0}\".format(type(colCreateDate)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4SvgG2Sjj5BW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c9d4dd7-ad87-4fb3-a7cf-2948e03f0888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+--------------------+\n",
            "|  id|       Creation_date|             Content|\n",
            "+----+--------------------+--------------------+\n",
            "|1165|2013-11-10 19:37:...|&lt;p&gt;The infi...|\n",
            "|1166|2013-11-10 19:44:...|&lt;p&gt;Come cre...|\n",
            "|1167|2013-11-10 19:58:...|&lt;p&gt;Il verbo...|\n",
            "|1168|2013-11-10 22:03:...|&lt;p&gt;As part ...|\n",
            "|1169|2013-11-10 22:15:...|&lt;p&gt;&lt;em&g...|\n",
            "+----+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ... and create a DataFrame from Column objects, by renaming the columns\n",
        "dfIdBodyDate = dfSE.select(colId,\n",
        "                              colCreateDate.alias(\"Creation_date\"),\n",
        "                              dfSE.body.alias(\"Content\"))\n",
        "dfIdBodyDate.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw45U9EYj9Nh"
      },
      "source": [
        "#### Select columns by using expressions\n",
        "\n",
        "To select columns using SQL expressions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "mSTG7pXokAd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d1ad46-ca71-4c10-c33e-32bb71f9a61f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------------------+--------------------+\n",
            "|  ID|       Creation_date|             Content|\n",
            "+----+--------------------+--------------------+\n",
            "|1165|2013-11-10 19:37:...|&lt;p&gt;The infi...|\n",
            "|1166|2013-11-10 19:44:...|&lt;p&gt;Come cre...|\n",
            "|1167|2013-11-10 19:58:...|&lt;p&gt;Il verbo...|\n",
            "|1168|2013-11-10 22:03:...|&lt;p&gt;As part ...|\n",
            "|1169|2013-11-10 22:15:...|&lt;p&gt;&lt;em&g...|\n",
            "+----+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import expr\n",
        "# Same DataFrame as before but using expressions\n",
        "dfIdDateBodyExpr = dfSE.select(\n",
        "                           expr(\"id AS ID\"),\n",
        "                           expr('creationDate AS Creation_date'),\n",
        "                           expr(\"body AS Content\"))\n",
        "dfIdDateBodyExpr.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "jO43v_chkCg-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e048ac6d-ef0d-4c72-85f1-22bcb0f1cbec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+----------+\n",
            "|nComs|        lastActivity|userId|                body|score|        creationDate|numViewed|               title|                tags|nAnswers|acceptedAnswerId|postType|  id|ValidReply|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+----------+\n",
            "|    4|2013-11-11 18:21:...|    17|&lt;p&gt;The infi...|   23|2013-11-10 19:37:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1165|     false|\n",
            "|    5|2013-11-10 20:31:...|    12|&lt;p&gt;Come cre...|    1|2013-11-10 19:44:...|       61|Cosa sapreste dir...| &lt;word-choice&gt;|       1|            NULL|       1|1166|      true|\n",
            "|    2|2013-11-10 20:31:...|    17|&lt;p&gt;Il verbo...|    5|2013-11-10 19:58:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1167|     false|\n",
            "|    1|2014-07-25 13:15:...|   154|&lt;p&gt;As part ...|   11|2013-11-10 22:03:...|      187|Ironic constructi...|&lt;english-compa...|       4|            1170|       1|1168|      true|\n",
            "|    0|2013-11-10 22:15:...|    70|&lt;p&gt;&lt;em&g...|    3|2013-11-10 22:15:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1169|     false|\n",
            "|    2|2013-11-10 22:17:...|    17|&lt;p&gt;There's ...|    8|2013-11-10 22:17:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1170|     false|\n",
            "|    1|2013-11-11 09:51:...|    63|&lt;p&gt;As other...|    3|2013-11-11 09:51:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1171|     false|\n",
            "|    1|2013-11-12 23:57:...|    63|&lt;p&gt;The expr...|    1|2013-11-11 10:09:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1172|     false|\n",
            "|    9|2014-01-05 11:13:...|    63|&lt;p&gt;When I w...|    5|2013-11-11 10:28:...|      122|Is &quot;scancell...|&lt;usage&gt;&lt;...|       3|            1181|       1|1173|      true|\n",
            "|    0|2013-11-11 10:58:...|    18|&lt;p&gt;Wow, wha...|    5|2013-11-11 10:58:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1174|     false|\n",
            "|    1|2014-01-16 19:56:...|    63|&lt;p&gt;Suppose ...|    4|2013-11-11 11:31:...|      114|How should I tran...|&lt;usage&gt;&lt;...|       2|            1177|       1|1175|      true|\n",
            "|    0|2013-11-11 14:36:...|    63|&lt;p&gt;Except w...|    3|2013-11-11 11:39:...|       58|Using a comma bet...|&lt;usage&gt;&lt;...|       2|            1182|       1|1176|      true|\n",
            "|    3|2014-01-16 19:56:...|    71|&lt;p&gt;Both you...|    6|2013-11-11 11:57:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1177|     false|\n",
            "|    0|2013-11-11 12:00:...|    12|&lt;blockquote&gt...|    1|2013-11-11 12:00:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1178|     false|\n",
            "|    0|2013-11-12 11:24:...|    63|&lt;p&gt;Comparin...|    3|2013-11-11 12:58:...|       60|Using the conditi...|&lt;usage&gt;&lt;...|       2|            1180|       1|1179|      true|\n",
            "|    4|2013-11-11 19:54:...|    18|&lt;p&gt;Using th...|    5|2013-11-11 13:48:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1180|     false|\n",
            "|    0|2013-11-11 18:20:...|   132|&lt;p&gt;I would ...|    8|2013-11-11 14:04:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1181|     false|\n",
            "|    1|2013-11-11 14:36:...|   132|&lt;p&gt;Putting ...|   11|2013-11-11 14:17:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1182|     false|\n",
            "|    2|2013-11-14 09:56:...|    22|&lt;p&gt;Many peo...|    6|2013-11-11 14:43:...|      321|Can Dante Alighie...|&lt;history&gt;&l...|       1|            1263|       1|1183|      true|\n",
            "|    2|2013-11-11 23:23:...|   159|&lt;p&gt;Sono un'...|    7|2013-11-11 18:19:...|      138|origine dell'espr...|&lt;idioms&gt;&lt...|       2|            1185|       1|1184|      true|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We can use more complex expressions\n",
        "dfSE.selectExpr(\"*\", # Select all columns and set ValidReply to True for those with, at least, one reply.\n",
        "                \"(nAnswers IS NOT NULL) as ValidReply\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3fIFG0MkHY0"
      },
      "source": [
        "### Rename, add and delete columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "w4-CC8StkJ1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26c16670-52eb-47ce-cd1a-80045855d39d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+----------------+-----+--------+\n",
            "|Creation_date          |Number_of_visits|score|postType|\n",
            "+-----------------------+----------------+-----+--------+\n",
            "|2013-11-10 19:37:54.187|NULL            |23   |2       |\n",
            "|2013-11-10 19:44:53.797|61              |1    |1       |\n",
            "|2013-11-10 19:58:02.1  |NULL            |5    |2       |\n",
            "|2013-11-10 22:03:41.027|187             |11   |1       |\n",
            "|2013-11-10 22:15:17.693|NULL            |3    |2       |\n",
            "|2013-11-10 22:17:22.38 |NULL            |8    |2       |\n",
            "|2013-11-11 09:51:11.22 |NULL            |3    |2       |\n",
            "|2013-11-11 10:09:05.117|NULL            |1    |2       |\n",
            "|2013-11-11 10:28:12.613|122             |5    |1       |\n",
            "|2013-11-11 10:58:02.62 |NULL            |5    |2       |\n",
            "|2013-11-11 11:31:02.343|114             |4    |1       |\n",
            "|2013-11-11 11:39:12.703|58              |3    |1       |\n",
            "|2013-11-11 11:57:03.723|NULL            |6    |2       |\n",
            "|2013-11-11 12:00:25.583|NULL            |1    |2       |\n",
            "|2013-11-11 12:58:38.137|60              |3    |1       |\n",
            "|2013-11-11 13:48:24.287|NULL            |5    |2       |\n",
            "|2013-11-11 14:04:00.753|NULL            |8    |2       |\n",
            "|2013-11-11 14:17:44.79 |NULL            |11   |2       |\n",
            "|2013-11-11 14:43:47.487|321             |6    |1       |\n",
            "|2013-11-11 18:19:12.253|138             |7    |1       |\n",
            "+-----------------------+----------------+-----+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Rename the creationDate column\n",
        "dfSE = dfSE.withColumnRenamed(\"creationDate\", \"Creation_date\")\n",
        "dfSE.cache()\n",
        "dfSE.select(\"Creation_date\",\n",
        "            dfSE.numViewed.alias(\"Number_of_visits\"),\n",
        "            \"score\",\n",
        "            \"postType\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "iFWWZ4askPrV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ef88877-2819-4b59-8b37-e61944aa7c0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+----+\n",
            "|nComs|        lastActivity|userId|                body|score|       Creation_date|numViewed|               title|                tags|nAnswers|acceptedAnswerId|postType|  id|ones|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+----+\n",
            "|    4|2013-11-11 18:21:...|    17|&lt;p&gt;The infi...|   23|2013-11-10 19:37:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1165|   1|\n",
            "|    5|2013-11-10 20:31:...|    12|&lt;p&gt;Come cre...|    1|2013-11-10 19:44:...|       61|Cosa sapreste dir...| &lt;word-choice&gt;|       1|            NULL|       1|1166|   1|\n",
            "|    2|2013-11-10 20:31:...|    17|&lt;p&gt;Il verbo...|    5|2013-11-10 19:58:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1167|   1|\n",
            "|    1|2014-07-25 13:15:...|   154|&lt;p&gt;As part ...|   11|2013-11-10 22:03:...|      187|Ironic constructi...|&lt;english-compa...|       4|            1170|       1|1168|   1|\n",
            "|    0|2013-11-10 22:15:...|    70|&lt;p&gt;&lt;em&g...|    3|2013-11-10 22:15:...|     NULL|                NULL|                NULL|    NULL|            NULL|       2|1169|   1|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Add a new column 'ones' with all its values set to 1\n",
        "from pyspark.sql.functions import lit\n",
        "# lit transforms a literal in Python to Spark internal format\n",
        "# (in this example, IntegerType)\n",
        "dfSE = dfSE.withColumn(\"ones\", lit(1))\n",
        "dfSE.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "5wWzrupfkRth",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b75cbfd-a333-4e83-c339-26d9b3b3fd6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nComs',\n",
              " 'lastActivity',\n",
              " 'userId',\n",
              " 'body',\n",
              " 'score',\n",
              " 'Creation_date',\n",
              " 'numViewed',\n",
              " 'title',\n",
              " 'tags',\n",
              " 'nAnswers',\n",
              " 'acceptedAnswerId',\n",
              " 'postType',\n",
              " 'id']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Removes a column using drop\n",
        "dfSE = dfSE.drop(col(\"ones\"))\n",
        "dfSE.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsxTogrdkWt0"
      },
      "source": [
        "### Delete null and duplicated values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "0XT8uw47kY2k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c3bd13-9e20-4047-e9e6-6bc8b8cef248"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial number or rows: 1261; number of non null rows: 222\n"
          ]
        }
      ],
      "source": [
        "# Remove all rows that have null on any of their columns\n",
        "dfNoNulls = dfSE.dropna(\"any\")\n",
        "print(\"Initial number or rows: {0}; number of non null rows: {1}\"\n",
        "       .format(dfSE.count(), dfNoNulls.count()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "O0xh2BW5ka_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fd22b74-742f-4b22-96b0-c5450aa8765a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with all columns set to null: 0\n"
          ]
        }
      ],
      "source": [
        "# Remove rows that have null on all their columns\n",
        "dfNeitherNull = dfSE.dropna(\"all\")\n",
        "print(\"Number of rows with all columns set to null: {0}\"\n",
        "       .format(dfSE.count() - dfNeitherNull.count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "NYKhJBTQkdbR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f6880b-04b3-4e84-f54e-6e8b020afe89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicated rows: 0\n"
          ]
        }
      ],
      "source": [
        "# Remove duplicated rows\n",
        "dfWithoutDuplicates = dfSE.dropDuplicates()\n",
        "print(\"Number of duplicated rows: {0}\"\n",
        "       .format(dfSE.count() - dfWithoutDuplicates.count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "-Fgz5rXhkf-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b959e6ad-1175-46e8-fd85-95b0a52bb48b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique users: 218\n"
          ]
        }
      ],
      "source": [
        "# Remove rows when a given column is duplicated\n",
        "dfWithoutDuplicatedUser = dfSE.dropDuplicates([\"userId\"])\n",
        "print(\"Number of unique users: {0}\"\n",
        "       .format(dfWithoutDuplicatedUser.count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "B8CSyfr1kjWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c43ab92-de3e-4c18-f358-72bc93f14db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with numViewed AND acceptedAnswerId not null: 222\n",
            "Number of rows with numViewed OR acceptedAnswerId not null: 374\n"
          ]
        }
      ],
      "source": [
        "# Other examples\n",
        "dfNoNullnumViewedAcceptedAnswerId = dfSE.dropna(\"any\", subset=[\"numViewed\", \"acceptedAnswerId\"])\n",
        "print(\"Number of rows with numViewed AND acceptedAnswerId not null: {0}\"\n",
        "       .format(dfNoNullnumViewedAcceptedAnswerId.count()))\n",
        "\n",
        "dfNoNullnumViewedAcceptedAnswerId = dfSE.dropna(\"all\", subset=[\"numViewed\", \"acceptedAnswerId\"])\n",
        "print(\"Number of rows with numViewed OR acceptedAnswerId not null: {0}\"\n",
        "       .format(dfNoNullnumViewedAcceptedAnswerId.count()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR8rAZGCkln-"
      },
      "source": [
        "### Replacing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "jGtTf0FmkuXv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7791a490-6221-415d-923f-4ea2fe65c33f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|nComs|        lastActivity|userId|                body|score|       Creation_date|numViewed|               title|                tags|nAnswers|acceptedAnswerId|postType|  id|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|    4|2013-11-11 18:21:...|    17|&lt;p&gt;The infi...|   23|2013-11-10 19:37:...|        0|                NULL|                NULL|       0|            NULL|       2|1165|\n",
            "|    5|2013-11-10 20:31:...|    12|&lt;p&gt;Come cre...|    1|2013-11-10 19:44:...|       61|Cosa sapreste dir...| &lt;word-choice&gt;|       1|            NULL|       1|1166|\n",
            "|    2|2013-11-10 20:31:...|    17|&lt;p&gt;Il verbo...|    5|2013-11-10 19:58:...|        0|                NULL|                NULL|       0|            NULL|       2|1167|\n",
            "|    1|2014-07-25 13:15:...|   154|&lt;p&gt;As part ...|   11|2013-11-10 22:03:...|      187|Ironic constructi...|&lt;english-compa...|       4|            1170|       1|1168|\n",
            "|    0|2013-11-10 22:15:...|    70|&lt;p&gt;&lt;em&g...|    3|2013-11-10 22:15:...|        0|                NULL|                NULL|       0|            NULL|       2|1169|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Replace with '0' all null values in the numVistas and nAnswers fields\n",
        "dfSE = dfSE.fillna(0, subset=[\"numViewed\", \"nAnswers\"])\n",
        "dfSE.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ILZkZtlAkwd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c57f8933-ae25-4293-e2ed-0173e0592ee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------------+\n",
            "|  id|acceptedAnswerId|\n",
            "+----+----------------+\n",
            "|1165|            NULL|\n",
            "|1166|            NULL|\n",
            "|1167|            NULL|\n",
            "|1168|            1170|\n",
            "|1169|            NULL|\n",
            "|1170|            NULL|\n",
            "|1171|            NULL|\n",
            "|1172|            NULL|\n",
            "|1173|            1181|\n",
            "|1174|            NULL|\n",
            "+----+----------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+----+----------------+\n",
            "|  id|acceptedAnswerId|\n",
            "+----+----------------+\n",
            "|1165|            NULL|\n",
            "|1166|            NULL|\n",
            "|1167|            NULL|\n",
            "|1168|            3000|\n",
            "|1169|            NULL|\n",
            "|3000|            NULL|\n",
            "|1171|            NULL|\n",
            "|1172|            NULL|\n",
            "|1173|            1181|\n",
            "|1174|            NULL|\n",
            "+----+----------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Replace the value 1170 with 3000 in columns \"id\" and \"acceptedAnswerId\"\n",
        "dfSE.select(\"id\", \"acceptedAnswerId\").show(10)\n",
        "dfSE.replace(1170, 3000, subset=[\"id\", \"acceptedAnswerId\"])\\\n",
        "    .select(\"id\", \"acceptedAnswerId\")\\\n",
        "    .show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0AhRhpzky7X"
      },
      "source": [
        "## Saving DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVR4GjW2k2S6"
      },
      "source": [
        "As for reading, Spark can save DateFrames in multiple formats:\n",
        "\n",
        "- CSV, JSON, Parquet, Hadoop...\n",
        "\n",
        "It can write them as well on a database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "EY8vG9xbk78E"
      },
      "outputs": [],
      "source": [
        "# Save the dfSE DataFrame in JSON format\n",
        "#dfSE.write.format(\"json\").mode(\"overwrite\").save(\"/content/dfSE.json\")\n",
        "dfSE.write.json(os.environ[\"DRIVE_DATA\"] + \"dfSE.json\",mode=\"overwrite\")\n",
        "\n",
        "#!mv /content/dfSE.json \"$DRIVE_DATA\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "qZdDPlv1lGzn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e979bef-0482-442e-adaf-4a8f9a7dba2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1.4M\n",
            "-rw------- 1 root root 1.4M Nov 25 13:41 part-00000-3ad09b66-4ebc-4c66-8342-066dea7211d2-c000.json\n",
            "-rw------- 1 root root  11K Nov 25 13:41 .part-00000-3ad09b66-4ebc-4c66-8342-066dea7211d2-c000.json.crc\n",
            "-rw------- 1 root root    0 Nov 25 13:41 _SUCCESS\n",
            "-rw------- 1 root root    8 Nov 25 13:41 ._SUCCESS.crc\n"
          ]
        }
      ],
      "source": [
        "!ls -alh \"$DRIVE_DATA\"/dfSE.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "P9Q-63hElJYQ"
      },
      "outputs": [],
      "source": [
        "# Save the DataFrame using Parquet\n",
        "dfSE.write.format(\"parquet\")\\\n",
        "    .mode(\"overwrite\")\\\n",
        "    .save(os.environ[\"DRIVE_DATA\"] + \"dfSE.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "cp6xMAnLlMJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec4f0e9-c53d-4a9c-e535-67259ba8d660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 620K\n",
            "-rw------- 1 root root 615K Nov 25 13:41 part-00000-54666160-c9a1-46c6-a342-2cc196f61a4b-c000.snappy.parquet\n",
            "-rw------- 1 root root 4.9K Nov 25 13:41 .part-00000-54666160-c9a1-46c6-a342-2cc196f61a4b-c000.snappy.parquet.crc\n",
            "-rw------- 1 root root    0 Nov 25 13:41 _SUCCESS\n",
            "-rw------- 1 root root    8 Nov 25 13:41 ._SUCCESS.crc\n"
          ]
        }
      ],
      "source": [
        "# Parquet uses by default the Snappy compressed format\n",
        "!ls -alh \"$DRIVE_DATA\"/dfSE.parquet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPpyVB30lPd-"
      },
      "source": [
        "It will create as many files as there are partitions in the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "yUTF4Q8QlRhI"
      },
      "outputs": [],
      "source": [
        "dfSE2 = dfSE.repartition(2)\n",
        "# Save the DataFrame using Parquet, with gzip compression\n",
        "dfSE2.write.format(\"parquet\")\\\n",
        "     .mode(\"overwrite\")\\\n",
        "     .option(\"compression\", \"gzip\")\\\n",
        "     .save(os.environ[\"DRIVE_DATA\"] + \"/dfSE2.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "yuypMiRilTaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af6b892-020e-4b74-f73b-aa3f4e84e422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 419K\n",
            "-rw------- 1 root root 203K Nov 25 13:42 part-00000-cb5d7ac4-7144-42a0-948e-31c9031217b1-c000.gz.parquet\n",
            "-rw------- 1 root root 1.6K Nov 25 13:42 .part-00000-cb5d7ac4-7144-42a0-948e-31c9031217b1-c000.gz.parquet.crc\n",
            "-rw------- 1 root root 212K Nov 25 13:42 part-00001-cb5d7ac4-7144-42a0-948e-31c9031217b1-c000.gz.parquet\n",
            "-rw------- 1 root root 1.7K Nov 25 13:42 .part-00001-cb5d7ac4-7144-42a0-948e-31c9031217b1-c000.gz.parquet.crc\n",
            "-rw------- 1 root root    0 Nov 25 13:42 _SUCCESS\n",
            "-rw------- 1 root root    8 Nov 25 13:42 ._SUCCESS.crc\n"
          ]
        }
      ],
      "source": [
        "!ls -alh \"$DRIVE_DATA\"/dfSE2.parquet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuQmqkp1lbU9"
      },
      "source": [
        "### Partitioning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2YPJVuWlfTB"
      },
      "source": [
        "Spark can partition and save a file using the value of a given column\n",
        "\n",
        "- A directory is created for each different value in the partitioning column\n",
        "    - All data associated to that value are stored in that directory\n",
        "- It simplifies the access to the values associated to a given key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "JMXPmB-6lii6"
      },
      "outputs": [],
      "source": [
        "# Save our DataFrame partitioned by the userID field (using Parquet)\n",
        "dfSE.write.format(\"parquet\")\\\n",
        "    .mode(\"overwrite\")\\\n",
        "    .partitionBy(\"userId\")\\\n",
        "    .save(os.environ[\"DRIVE_DATA\"] + \"dfSE-partition.parquet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "2HOlEv6olkyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78539ebf-2cbb-4d7a-bc4d-522b7bf78b8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4.5K\n",
            "-rw------- 1 root root 4.4K Nov 25 13:44 part-00000-e4717893-b646-48d6-992d-e91f2aa8cf91.c000.snappy.parquet\n"
          ]
        }
      ],
      "source": [
        "#!ls -lh \"$DRIVE_DATA\"dfSE-partition.parquet\n",
        "!ls -lh \"$DRIVE_DATA\"dfSE-partition.parquet/userId=10\n",
        "#rm -rf \"$DRIVE_DATA\"dfSE-partition.parquet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkJSOev3XOPn"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Exercises\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3ULPx4Y1LiR"
      },
      "source": [
        "## Exercise 3.1: Word count\n",
        "\n",
        "Count the number of words *per line* in the $DRIVE_DATA/quijote.txt file.\n",
        "\n",
        "Repeat the exercise but this time counting the number of words *in the whole file*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c7Q_ljrX5RtE"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F\n",
        "# so that we can use the F.split() function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Charger le fichier texte dans un DataFrame\n",
        "file_path = os.environ[\"DRIVE_DATA\"] + \"quijote.txt\"\n",
        "df = spark.read.text(file_path).withColumnRenamed(\"value\", \"line\")\n",
        "\n",
        "# Étape 2 : Compter les mots par ligne\n",
        "df_with_word_count = df.withColumn(\"word_count\", F.size(F.split(F.col(\"line\"), \" \")))\n",
        "df_with_word_count.show(10, truncate=False)\n",
        "\n",
        "# Étape 3 : Compter les mots dans tout le fichier\n",
        "total_word_count = df_with_word_count.agg(F.sum(\"word_count\").alias(\"total_word_count\"))\n",
        "total_word_count.show()\n"
      ],
      "metadata": {
        "id": "nrHIf1flWkM2",
        "outputId": "ef0b6fa7-6f9c-47a6-c09d-e28fd7b0dacf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------+----------+\n",
            "|line                                                                       |word_count|\n",
            "+---------------------------------------------------------------------------+----------+\n",
            "|The Project Gutenberg EBook of Don Quijote, by Miguel de Cervantes Saavedra|12        |\n",
            "|                                                                           |1         |\n",
            "|This eBook is for the use of anyone anywhere at no cost and with           |14        |\n",
            "|almost no restrictions whatsoever.  You may copy it, give it away or       |13        |\n",
            "|re-use it under the terms of the Project Gutenberg License included        |11        |\n",
            "|with this eBook or online at www.gutenberg.net                             |7         |\n",
            "|                                                                           |1         |\n",
            "|                                                                           |1         |\n",
            "|Title: Don Quijote                                                         |3         |\n",
            "|                                                                           |1         |\n",
            "+---------------------------------------------------------------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+----------------+\n",
            "|total_word_count|\n",
            "+----------------+\n",
            "|          393764|\n",
            "+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ph_2Rl7LX7o4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}