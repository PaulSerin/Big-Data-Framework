{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PaulSerin/Big-Data-Framework/blob/main/BDF_04_Operations_on_DataFrames.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-h_wDcNlH_K"
      },
      "source": [
        "#00 - Configuration of Apache Spark on Collaboratory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvD4HBMi0ohY"
      },
      "source": [
        "###Installing Java, Spark, and Findspark\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This code installs Apache Spark 2.2.1, Java 8, and [Findspark](https://github.com/minrk/findspark), a library that makes it easy for Python to find Spark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsAfQ0CrgnWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3f7c167-570c-49e6-ebe2-9d00cd9b6591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,172 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,501 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,323 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,734 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,223 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,452 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,512 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,616 kB]\n",
            "Fetched 23.9 MB in 5s (4,838 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "--2024-11-25 14:15:06--  http://apache.osuosl.org/spark/spark-3.5.3/spark-3.5.3-bin-hadoop3.tgz\n",
            "Resolving apache.osuosl.org (apache.osuosl.org)... 64.50.233.100, 64.50.236.52, 140.211.166.134, ...\n",
            "Connecting to apache.osuosl.org (apache.osuosl.org)|64.50.233.100|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 400864419 (382M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.5.3-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.5.3-bin-had 100%[===================>] 382.29M  25.4MB/s    in 19s     \n",
            "\n",
            "2024-11-25 14:15:25 (20.2 MB/s) - ‘spark-3.5.3-bin-hadoop3.tgz’ saved [400864419/400864419]\n",
            "\n",
            "spark-3.5.3-bin-hadoop3.tgz\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"SPARK_VERSION\"] = \"spark-3.5.3\"\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget  http://apache.osuosl.org/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n",
        "!echo $SPARK_VERSION-bin-hadoop3.tgz\n",
        "!rm $SPARK_VERSION-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4Kjvk_h1AHl"
      },
      "source": [
        "### Set Environment Variables\n",
        "Set the locations where Spark and Java are installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiOoj3rUgnVx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23d97a99-2b75-40e6-c915-a3ace5131459"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/spark': No such file or directory\n",
            "/content/spark/\n",
            "DRIVE_DATA=/content/gdrive/My Drive/Big Data Framework/data/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark/\"\n",
        "os.environ[\"DRIVE_DATA\"] = \"/content/gdrive/My Drive/Big Data Framework/data/\"\n",
        "\n",
        "!rm /content/spark\n",
        "!ln -s /content/$SPARK_VERSION-bin-hadoop3 /content/spark\n",
        "!export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin\n",
        "!echo $SPARK_HOME\n",
        "!env |grep  \"DRIVE_DATA\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwU28K5f1H3P"
      },
      "source": [
        "### Start a SparkSession\n",
        "This will start a local Spark session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgReRGl0y23D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4553dc46-36f7-4e65-96d7-d1ea594c653b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "PySpark version 3.5.3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "!python -V\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "# Example: shows the PySpark version\n",
        "print(\"PySpark version {0}\".format(sc.version))\n",
        "\n",
        "# Example: parallelise an array and show the 2 first elements\n",
        "sc.parallelize([2, 3, 4, 5, 6]).cache().take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBca_LsWxnx2"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "# We create a SparkSession object (or we retrieve it if it is already created)\n",
        "spark = SparkSession \\\n",
        ".builder \\\n",
        ".appName(\"My application\") \\\n",
        ".config(\"spark.some.config.option\", \"some-value\") \\\n",
        ".master(\"local[4]\") \\\n",
        ".getOrCreate()\n",
        "# We get the SparkContext\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7irzXK6Nvt8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b853e6-07bb-4801-fad6-84f66ab978d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkKGBZRvEwZL"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# 04 - Operations with DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcr9KTJbJI_4"
      },
      "source": [
        "We are going to see different operations that can be performed with DataFrames:\n",
        "\n",
        "  - Row filtering\n",
        "  - Sorting and grouping\n",
        "  - Joins\n",
        "  - Scalar functions and aggregations\n",
        "  - Using them with complex types\n",
        "  - Window functions\n",
        "  - User-defined functions\n",
        "\n",
        "We will end up seeing how to use SQL requests on DataFrames\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH1tMsjx8-sl"
      },
      "source": [
        "As for reading, Spark can save DateFrames in multiple formats:\n",
        "\n",
        "- CSV, JSON, Parquet, Hadoop...\n",
        "\n",
        "It can write them as well on a database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8HjKeILIiCI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d6f76b3-d1f0-4f5a-a2b9-dfea98ad58db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[nComs: int, lastActivity: timestamp, userId: bigint, body: string, score: int, Creation_date: timestamp, numViewed: int, title: string, tags: string, nAnswers: int, acceptedAnswerId: bigint, postType: tinyint, id: bigint]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "#Retrieve a DataFrame reading it from the Parquet format\n",
        "dfSE = spark.read\\\n",
        "            .format(\"parquet\")\\\n",
        "            .option(\"mode\", \"FAILFAST\")\\\n",
        "            .load(os.environ[\"DRIVE_DATA\"] + \"dfSE.parquet\")\n",
        "dfSE.cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QynVQ-HVfAmQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8710d58-0580-4b49-edd2-0e66011c66fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|nComs|        lastActivity|userId|                body|score|       Creation_date|numViewed|               title|                tags|nAnswers|acceptedAnswerId|postType|  id|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|    4|2013-11-11 18:21:...|    17|&lt;p&gt;The infi...|   23|2013-11-10 19:37:...|        0|                NULL|                NULL|       0|            NULL|       2|1165|\n",
            "|    5|2013-11-10 20:31:...|    12|&lt;p&gt;Come cre...|    1|2013-11-10 19:44:...|       61|Cosa sapreste dir...| &lt;word-choice&gt;|       1|            NULL|       1|1166|\n",
            "|    2|2013-11-10 20:31:...|    17|&lt;p&gt;Il verbo...|    5|2013-11-10 19:58:...|        0|                NULL|                NULL|       0|            NULL|       2|1167|\n",
            "|    1|2014-07-25 13:15:...|   154|&lt;p&gt;As part ...|   11|2013-11-10 22:03:...|      187|Ironic constructi...|&lt;english-compa...|       4|            1170|       1|1168|\n",
            "|    0|2013-11-10 22:15:...|    70|&lt;p&gt;&lt;em&g...|    3|2013-11-10 22:15:...|        0|                NULL|                NULL|       0|            NULL|       2|1169|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- nComs: integer (nullable = true)\n",
            " |-- lastActivity: timestamp (nullable = true)\n",
            " |-- userId: long (nullable = true)\n",
            " |-- body: string (nullable = true)\n",
            " |-- score: integer (nullable = true)\n",
            " |-- Creation_date: timestamp (nullable = true)\n",
            " |-- numViewed: integer (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- tags: string (nullable = true)\n",
            " |-- nAnswers: integer (nullable = true)\n",
            " |-- acceptedAnswerId: long (nullable = true)\n",
            " |-- postType: byte (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dfSE.show(5)\n",
        "dfSE.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG1IQyhIfHnb"
      },
      "source": [
        "## Filter operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hs2OsMefIXm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b04939e4-6841-4954-bfa3-6d85948543c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of posts with the word Italiano: 46\n",
            "\n",
            "Show the first line\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(nComs=0, lastActivity=datetime.datetime(2013, 11, 11, 21, 44, 11, 903000), userId=8, body=\"&lt;p&gt;&lt;strong&gt;Comma + ellipsis&lt;/strong&gt; is used mainly for listing the numbers (as you would do in mathematics: &lt;em&gt;1,2,3,...&lt;/em&gt;). Still, there should be no space between comma and ellipsis.&lt;br&gt;&lt;strong&gt;Ellipsis only&lt;/strong&gt; is used for listing the words (see the grammar examples &lt;a href=&quot;http://books.google.se/books?id=BCRXQfia26wC&amp;amp;pg=PA73&amp;amp;dq=puntini%20sospensione&amp;amp;hl=en&amp;amp;sa=X&amp;amp;ei=QUyBUp-UBejy4QTc5YHoBA&amp;amp;ved=0CC8Q6AEwAA#v=onepage&amp;amp;q=puntini%20sospensione&amp;amp;f=false&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt; or &lt;a href=&quot;http://books.google.se/books?id=Xe2pkxDqG20C&amp;amp;pg=PA206&amp;amp;dq=puntini%20sospensione&amp;amp;hl=en&amp;amp;sa=X&amp;amp;ei=QUyBUp-UBejy4QTc5YHoBA&amp;amp;ved=0CGcQ6AEwBw#v=onepage&amp;amp;q=puntini%20sospensione&amp;amp;f=false&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt; or &lt;a href=&quot;http://www.treccani.it/enciclopedia/puntini_%28Enciclopedia-dell%27Italiano%29/&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt;).&lt;br&gt;&lt;strong&gt;Eccetera&lt;/strong&gt; means that the list is being continued, hence it could not use additional comma or ellipsis. The only right combination with &lt;em&gt;eccetera&lt;/em&gt; is the last one, and even in this case &lt;a href=&quot;http://www.treccani.it/vocabolario/eccetera/&quot; rel=&quot;nofollow&quot;&gt;it's commonly&lt;/a&gt; cut down to &lt;em&gt;ecc.&lt;/em&gt;&lt;/p&gt;\", score=1, Creation_date=datetime.datetime(2013, 11, 11, 21, 36, 34, 360000), numViewed=0, title=None, tags=None, nAnswers=0, acceptedAnswerId=None, postType=2, id=1196)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Select those posts that contain the word 'Italiano' in their body\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "colBody = col(\"body\")\n",
        "dfItaliano = dfSE.filter(colBody.like('%Italiano%'))\n",
        "\n",
        "print(\"Number of posts with the word Italiano: {0}\\n\".format(dfItaliano.count()))\n",
        "\n",
        "print(\"Show the first line\")\n",
        "dfItaliano.take(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mlCziy5fPI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2781a307-fdf1-4743-f486-df1f7b16b787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of questions with an accepted reply: 222\n",
            "+-----------------------+---------+----------------+\n",
            "|Date_of_creation       |Post Type|acceptedAnswerId|\n",
            "+-----------------------+---------+----------------+\n",
            "|2013-11-10 22:03:41.027|1        |1170            |\n",
            "|2013-11-11 10:28:12.613|1        |1181            |\n",
            "|2013-11-11 11:31:02.343|1        |1177            |\n",
            "|2013-11-11 11:39:12.703|1        |1182            |\n",
            "|2013-11-11 12:58:38.137|1        |1180            |\n",
            "|2013-11-11 14:43:47.487|1        |1263            |\n",
            "|2013-11-11 18:19:12.253|1        |1185            |\n",
            "|2013-11-11 21:01:13.34 |1        |1212            |\n",
            "|2013-11-11 21:01:47.523|1        |1195            |\n",
            "|2013-11-12 09:31:34.54 |1        |1202            |\n",
            "|2013-11-12 10:57:21.793|1        |1216            |\n",
            "|2013-11-12 11:03:26.287|1        |1207            |\n",
            "|2013-11-12 13:12:01.78 |1        |1226            |\n",
            "|2013-11-12 13:34:23.74 |1        |1227            |\n",
            "|2013-11-12 13:38:23.663|1        |1223            |\n",
            "|2013-11-12 14:11:05.767|1        |1228            |\n",
            "|2013-11-12 14:14:50.85 |1        |1235            |\n",
            "|2013-11-12 14:49:07.607|1        |1230            |\n",
            "|2013-11-12 15:38:30.917|1        |1234            |\n",
            "|2013-11-12 23:50:21.267|1        |1247            |\n",
            "+-----------------------+---------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Retrieve the questions (postType == 1) which have an accepted reply (acceptedAnswerID != null)\n",
        "# Note: where() is an alias of filter()\n",
        "\n",
        "colPostType = col(\"postType\")\n",
        "colAcceptedReplyId = col(\"acceptedAnswerId\")\n",
        "\n",
        "dfQuestionWithAcceptedReply = dfSE\\\n",
        "                    .where((colPostType == 1) & (colAcceptedReplyId.isNotNull()))\\\n",
        "                    .withColumnRenamed(\"Creation_date\", \"Date_of_creation\")\n",
        "\n",
        "print(\"Number of questions with an accepted reply: {0}\"\\\n",
        "      .format(dfQuestionWithAcceptedReply.count()))\n",
        "\n",
        "dfQuestionWithAcceptedReply.cache()\n",
        "\n",
        "dfQuestionWithAcceptedReply\\\n",
        "        .select(\"Date_of_creation\", colPostType.alias(\"Post Type\"), colAcceptedReplyId)\\\n",
        "        .show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQB_ERIcfTGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04b739f2-9af3-4cdc-c6b1-86744d5e0c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+--------+----------------+\n",
            "|Date_of_creation       |postType|acceptedAnswerId|\n",
            "+-----------------------+--------+----------------+\n",
            "|2014-06-01 13:23:00.687|1       |1994            |\n",
            "|2014-06-01 13:28:46.887|1       |1993            |\n",
            "|2014-06-04 07:02:38.767|1       |1997            |\n",
            "|2014-06-04 12:59:36.857|1       |2010            |\n",
            "|2014-06-04 20:26:02.053|1       |2004            |\n",
            "|2014-06-05 12:04:44.453|1       |2006            |\n",
            "|2014-06-07 19:43:33.963|1       |2012            |\n",
            "|2014-06-09 08:51:01.853|1       |2016            |\n",
            "|2014-06-27 14:18:10.363|1       |2025            |\n",
            "|2014-06-29 18:34:55.657|1       |2031            |\n",
            "+-----------------------+--------+----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Keep the entries corresponding to June 2014\n",
        "from datetime import date\n",
        "\n",
        "colCreationDate = col(\"Date_of_creation\")\n",
        "\n",
        "dfQuestionWithAcceptedReplyJun14 = dfQuestionWithAcceptedReply\\\n",
        "                    .filter((colCreationDate >= date(2014,6,1)) &\n",
        "                            (colCreationDate <= date(2014,6,30)))\n",
        "\n",
        "dfQuestionWithAcceptedReplyJun14.select(colCreationDate, colPostType, colAcceptedReplyId).show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzquPGw-fjHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81e832aa-d356-43f4-df23-7ccfcbf590ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+---------+-----+------------------+\n",
            "|Date_of_creation       |numViewed|score|ratio             |\n",
            "+-----------------------+---------+-----+------------------+\n",
            "|2013-11-11 14:43:47.487|321      |6    |53.5              |\n",
            "|2013-11-12 14:14:50.85 |579      |14   |41.357142857142854|\n",
            "|2013-11-14 15:44:50.99 |653      |7    |93.28571428571429 |\n",
            "|2013-11-23 09:09:04.993|181      |3    |60.333333333333336|\n",
            "|2013-11-23 09:15:29.247|474      |3    |158.0             |\n",
            "|2013-11-26 20:08:13.423|79       |2    |39.5              |\n",
            "|2013-11-27 08:05:11.63 |172      |1    |172.0             |\n",
            "|2013-11-28 08:26:19.477|378      |5    |75.6              |\n",
            "|2013-11-29 14:52:32.28 |57       |1    |57.0              |\n",
            "|2013-12-01 18:11:27.07 |114      |1    |114.0             |\n",
            "|2013-12-08 03:20:58.563|313      |5    |62.6              |\n",
            "|2013-12-14 21:31:54.963|154      |4    |38.5              |\n",
            "|2013-12-15 17:39:53.017|330      |7    |47.142857142857146|\n",
            "|2013-12-16 13:50:19.943|489      |6    |81.5              |\n",
            "|2013-12-19 09:05:47.3  |174      |2    |87.0              |\n",
            "|2013-12-19 23:01:35.55 |463      |7    |66.14285714285714 |\n",
            "|2013-12-20 17:49:42.653|72       |2    |36.0              |\n",
            "|2013-12-20 21:47:06.63 |171      |3    |57.0              |\n",
            "|2013-12-21 14:05:32.447|144      |2    |72.0              |\n",
            "|2013-12-27 14:45:38.683|445      |7    |63.57142857142857 |\n",
            "+-----------------------+---------+-----+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Add a column with the ratio between the number of visits and the score of the question\n",
        "colNumViews = col(\"numViewed\")\n",
        "colPoints = col(\"score\")\n",
        "dfQuestionWithAcceptedReplyRatio = dfQuestionWithAcceptedReply.withColumn(\"ratio\", colNumViews/colPoints)\n",
        "\n",
        "# Shows some columns with ratio > 35\n",
        "colRatio = col(\"ratio\")\n",
        "dfQuestionWithAcceptedReplyRatio.filter(colRatio > 35)\\\n",
        "                        .select(colCreationDate, colNumViews, colPoints, colRatio)\\\n",
        "                        .show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk517hNifmmC"
      },
      "source": [
        "## Sorting and grouping operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_l3saJy9fnZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35849895-e880-4423-b82a-9aaadf3fb420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+---------+\n",
            "|Date_of_creation       |numViewed|\n",
            "+-----------------------+---------+\n",
            "|2014-03-06 19:51:16.093|711      |\n",
            "|2013-11-14 15:44:50.99 |653      |\n",
            "|2013-11-12 14:14:50.85 |579      |\n",
            "|2013-11-05 21:57:56.813|557      |\n",
            "|2013-12-16 13:50:19.943|489      |\n",
            "|2013-11-23 09:15:29.247|474      |\n",
            "|2014-09-10 05:53:39.14 |465      |\n",
            "|2013-12-19 23:01:35.55 |463      |\n",
            "|2014-08-20 06:06:02.457|455      |\n",
            "|2013-12-27 14:45:38.683|445      |\n",
            "+-----------------------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Sorting by viewCount\n",
        "dfQuestionWithAcceptedReply.orderBy(colNumViews, ascending=False)\\\n",
        "                  .select(colCreationDate, colNumViews)\\\n",
        "                  .show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B79cu3aqfpmR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c5deb6d-af5d-4d92-f4ad-1e3b6da55a2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.group.GroupedData'>\n"
          ]
        }
      ],
      "source": [
        "# Grouping by the userId column\n",
        "colUserId = col(\"userId\")\n",
        "groupByUser = dfQuestionWithAcceptedReply.groupBy(colUserId)\n",
        "print(type(groupByUser))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQkxaC1dfrvh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da42e928-e585-4376-8251-7e99e57d9ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with the number of posts by user\n",
            "root\n",
            " |-- userId: long (nullable = true)\n",
            " |-- count: long (nullable = false)\n",
            "\n",
            "+-----------+---------------+\n",
            "|User number|Number of posts|\n",
            "+-----------+---------------+\n",
            "|          8|              4|\n",
            "|         12|             20|\n",
            "|         17|              3|\n",
            "|         18|              2|\n",
            "|         22|             11|\n",
            "|         37|              2|\n",
            "|         48|              1|\n",
            "|         53|              2|\n",
            "|         56|              5|\n",
            "|         61|              1|\n",
            "+-----------+---------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"DataFrame with the number of posts by user\")\n",
        "dfPostsByUser = groupByUser.count()\n",
        "dfPostsByUser.printSchema()\n",
        "\n",
        "colNPosts = col(\"count\")\n",
        "dfPostsByUser.select(colUserId.alias(\"User number\"),\n",
        "                        colNPosts.alias(\"Number of posts\"))\\\n",
        "                .orderBy(colUserId).show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6_KnTBoft2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43bc9612-c78a-4ffa-ad22-5079e8a19477"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with the average number of views per user\n",
            "+------+------------------+\n",
            "|userId|    avg(numViewed)|\n",
            "+------+------------------+\n",
            "|     8|             168.0|\n",
            "|    12|             141.1|\n",
            "|    17| 90.66666666666667|\n",
            "|    18|             144.0|\n",
            "|    22|201.36363636363637|\n",
            "|    37|             312.0|\n",
            "|    48|             127.0|\n",
            "|    53|              70.5|\n",
            "|    56|             115.6|\n",
            "|    61|             338.0|\n",
            "+------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"DataFrame with the average number of views per user\")\n",
        "dfAvgPerUser = groupByUser.avg(\"numViewed\")\n",
        "dfAvgPerUser.orderBy(colUserId).show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWD4Hv7rfv0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09ccbbcc-8637-4fb7-80f2-8f8689a128ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtain the previous tables with a single operation\n",
            "root\n",
            " |-- userId: long (nullable = true)\n",
            " |-- avg(numViewed): double (nullable = true)\n",
            " |-- count(userId): long (nullable = false)\n",
            "\n",
            "+-----------+---------------+------------------+\n",
            "|User number|Number of posts|     Views average|\n",
            "+-----------+---------------+------------------+\n",
            "|          8|              4|             168.0|\n",
            "|         12|             20|             141.1|\n",
            "|         17|              3| 90.66666666666667|\n",
            "|         18|              2|             144.0|\n",
            "|         22|             11|201.36363636363637|\n",
            "|         37|              2|             312.0|\n",
            "|         48|              1|             127.0|\n",
            "|         53|              2|              70.5|\n",
            "|         56|              5|             115.6|\n",
            "|         61|              1|             338.0|\n",
            "+-----------+---------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The 'agg' method allows grouping operations expressed as a dictionary {column_name:operation}\n",
        "print(\"Obtain the previous tables with a single operation\")\n",
        "dfCountAvg = groupByUser.agg({\"userId\":\"count\", \"numViewed\":\"avg\"})\n",
        "dfCountAvg.printSchema()\n",
        "\n",
        "colCount = col(\"count(userId)\")\n",
        "colMedia = col(\"avg(numViewed)\")\n",
        "dfCountAvg.select(colUserId.alias(\"User number\"),\n",
        "                   colCount.alias(\"Number of posts\"),\n",
        "                   colMedia.alias(\"Views average\"))\\\n",
        "                  .orderBy(colUserId).show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAiW6qzffyN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdcbc7d4-4734-428a-ebf7-618ce9e1417d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+-----+\n",
            "|userId|postType|count|\n",
            "+------+--------+-----+\n",
            "|     4|       1|    1|\n",
            "|     4|       2|    1|\n",
            "|     5|       2|   10|\n",
            "|     6|       2|    2|\n",
            "|     8|       1|    6|\n",
            "|     8|       2|   36|\n",
            "|     8|       4|   52|\n",
            "|     8|       5|   52|\n",
            "|    10|       2|    1|\n",
            "|    12|       1|   95|\n",
            "|    12|       2|   14|\n",
            "|    13|       2|    1|\n",
            "|    14|       2|    2|\n",
            "|    15|       2|    2|\n",
            "|    17|       1|    3|\n",
            "|    17|       2|   28|\n",
            "|    18|       1|    4|\n",
            "|    18|       2|   27|\n",
            "|    19|       2|   13|\n",
            "|    22|       1|   14|\n",
            "+------+--------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Grouping on two columns\n",
        "dfSE.groupBy(colUserId, colPostType)\\\n",
        "    .count()\\\n",
        "    .sort(colUserId, colPostType)\\\n",
        "    .show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVki8IlIf3kU"
      },
      "source": [
        "A description of the functions used with GroupedData can be found on https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#grouping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JHE1mPef7BI"
      },
      "source": [
        "### Advanced grouping\n",
        "\n",
        "It is possible to group data on more than one column: `Rollups` and `Cube`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5N2QB-qf-Dp"
      },
      "source": [
        "#### Rollups\n",
        "\n",
        "Grouping by multiple columns, including aggregations by the first column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTOuTUEhf0w4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6adb9f3b-e18d-466c-a8d0-6d6c12025f49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.group.GroupedData'>\n"
          ]
        }
      ],
      "source": [
        "# For each user, count the number of questions (postType == 1) and the number of replies (postType == 2)\n",
        "rollupPerUserAndPostType = dfSE.rollup(\"userId\", \"postType\")\n",
        "print(type(rollupPerUserAndPostType))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4k-5enfgBt0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf044b89-2691-4761-c2e5-9ff8b2a18e08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- userId: long (nullable = true)\n",
            " |-- postType: byte (nullable = true)\n",
            " |-- count: long (nullable = false)\n",
            "\n",
            "+-----------+---------+---------------+\n",
            "|User number|Post type|Number of posts|\n",
            "+-----------+---------+---------------+\n",
            "|       NULL|     NULL|           1261|\n",
            "|          4|     NULL|              2|\n",
            "|          4|        1|              1|\n",
            "|          4|        2|              1|\n",
            "|          5|     NULL|             10|\n",
            "|          5|        2|             10|\n",
            "|          6|     NULL|              2|\n",
            "|          6|        2|              2|\n",
            "|          8|     NULL|            146|\n",
            "|          8|        1|              6|\n",
            "|          8|        2|             36|\n",
            "|          8|        4|             52|\n",
            "|          8|        5|             52|\n",
            "|         10|     NULL|              1|\n",
            "|         10|        2|              1|\n",
            "|         12|     NULL|            109|\n",
            "|         12|        1|             95|\n",
            "|         12|        2|             14|\n",
            "|         13|     NULL|              1|\n",
            "|         13|        2|              1|\n",
            "|         14|     NULL|              2|\n",
            "|         14|        2|              2|\n",
            "|         15|     NULL|              2|\n",
            "|         15|        2|              2|\n",
            "|         17|     NULL|             31|\n",
            "|         17|        1|              3|\n",
            "|         17|        2|             28|\n",
            "|         18|     NULL|             31|\n",
            "|         18|        1|              4|\n",
            "|         18|        2|             27|\n",
            "|         19|     NULL|             13|\n",
            "|         19|        2|             13|\n",
            "|         22|     NULL|             44|\n",
            "|         22|        1|             14|\n",
            "|         22|        2|             22|\n",
            "|         22|        4|              4|\n",
            "|         22|        5|              4|\n",
            "|         37|     NULL|             64|\n",
            "|         37|        1|              5|\n",
            "|         37|        2|             59|\n",
            "|         41|     NULL|              2|\n",
            "|         41|        2|              2|\n",
            "|         48|     NULL|              3|\n",
            "|         48|        1|              1|\n",
            "|         48|        2|              2|\n",
            "|         53|     NULL|              2|\n",
            "|         53|        1|              2|\n",
            "|         56|     NULL|              5|\n",
            "|         56|        1|              5|\n",
            "|         57|     NULL|             10|\n",
            "|         57|        2|             10|\n",
            "|         61|     NULL|              1|\n",
            "|         61|        1|              1|\n",
            "|         63|     NULL|             53|\n",
            "|         63|        1|             25|\n",
            "|         63|        2|             28|\n",
            "|         68|     NULL|              4|\n",
            "|         68|        1|              2|\n",
            "|         68|        2|              2|\n",
            "|         70|     NULL|             52|\n",
            "|         70|        2|             52|\n",
            "|         71|     NULL|              2|\n",
            "|         71|        2|              2|\n",
            "|         73|     NULL|              2|\n",
            "|         73|        1|              1|\n",
            "|         73|        2|              1|\n",
            "|         75|     NULL|              2|\n",
            "|         75|        1|              1|\n",
            "|         75|        2|              1|\n",
            "|         77|     NULL|              6|\n",
            "|         77|        1|              2|\n",
            "|         77|        2|              4|\n",
            "|         79|     NULL|              5|\n",
            "|         79|        1|              4|\n",
            "|         79|        2|              1|\n",
            "|         82|     NULL|              6|\n",
            "|         82|        1|              2|\n",
            "|         82|        2|              4|\n",
            "|         85|     NULL|              2|\n",
            "|         85|        1|              1|\n",
            "|         85|        2|              1|\n",
            "|         87|     NULL|              6|\n",
            "|         87|        2|              6|\n",
            "|         88|     NULL|              4|\n",
            "|         88|        1|              2|\n",
            "|         88|        2|              2|\n",
            "|         91|     NULL|              1|\n",
            "|         91|        1|              1|\n",
            "|         95|     NULL|             34|\n",
            "|         95|        1|              5|\n",
            "|         95|        2|             29|\n",
            "|         98|     NULL|              7|\n",
            "|         98|        2|              7|\n",
            "|         99|     NULL|              2|\n",
            "|         99|        1|              2|\n",
            "|        103|     NULL|              1|\n",
            "|        103|        2|              1|\n",
            "|        114|     NULL|              2|\n",
            "|        114|        1|              2|\n",
            "|        116|     NULL|              1|\n",
            "+-----------+---------+---------------+\n",
            "only showing top 100 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# DataFrame with the number of posts per user and 'Question' post type\n",
        "# Null fields are aggregation fields. For example:\n",
        "# null null = all posts\n",
        "# 4    null = all posts from user with id 4\n",
        "# 4    1    = all posts of type 1 from user with id 4\n",
        "# NOTE: disregard posts with types 4 and 5.\n",
        "dfPostPerUserAndType = rollupPerUserAndPostType.count()\n",
        "dfPostPerUserAndType.printSchema()\n",
        "dfPostPerUserAndType.select(colUserId.alias(\"User number\"),\n",
        "                             colPostType.alias(\"Post type\"),\n",
        "                             colNPosts.alias(\"Number of posts\"))\\\n",
        "                     .orderBy(colUserId,colPostType)\\\n",
        "                     .show(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OAwGuDbgE3A"
      },
      "source": [
        "#### Cubes\n",
        "\n",
        "Similar to Rollups, but going through all dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVNxjbsPgHSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eab133b-a133-489f-9708-94b83086af90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.group.GroupedData'>\n"
          ]
        }
      ],
      "source": [
        "groupByUserAndPostType = dfSE.cube(\"userId\", \"postType\")\n",
        "print(type(groupByUserAndPostType))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOcJXNHegJSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c7736f0-d661-4a70-81e4-d715c225232d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- userId: long (nullable = true)\n",
            " |-- postType: byte (nullable = true)\n",
            " |-- count: long (nullable = false)\n",
            "\n",
            "+-----------+---------+---------------+\n",
            "|User number|Post type|Number of posts|\n",
            "+-----------+---------+---------------+\n",
            "|       NULL|     NULL|           1261|\n",
            "|       NULL|        1|            374|\n",
            "|       NULL|        2|            765|\n",
            "|       NULL|        4|             64|\n",
            "|       NULL|        5|             58|\n",
            "|          4|     NULL|              2|\n",
            "|          4|        1|              1|\n",
            "|          4|        2|              1|\n",
            "|          5|     NULL|             10|\n",
            "|          5|        2|             10|\n",
            "|          6|     NULL|              2|\n",
            "|          6|        2|              2|\n",
            "|          8|     NULL|            146|\n",
            "|          8|        1|              6|\n",
            "|          8|        2|             36|\n",
            "|          8|        4|             52|\n",
            "|          8|        5|             52|\n",
            "|         10|     NULL|              1|\n",
            "|         10|        2|              1|\n",
            "|         12|     NULL|            109|\n",
            "|         12|        1|             95|\n",
            "|         12|        2|             14|\n",
            "|         13|     NULL|              1|\n",
            "|         13|        2|              1|\n",
            "|         14|     NULL|              2|\n",
            "|         14|        2|              2|\n",
            "|         15|     NULL|              2|\n",
            "|         15|        2|              2|\n",
            "|         17|     NULL|             31|\n",
            "|         17|        1|              3|\n",
            "|         17|        2|             28|\n",
            "|         18|     NULL|             31|\n",
            "|         18|        1|              4|\n",
            "|         18|        2|             27|\n",
            "|         19|     NULL|             13|\n",
            "|         19|        2|             13|\n",
            "|         22|     NULL|             44|\n",
            "|         22|        1|             14|\n",
            "|         22|        2|             22|\n",
            "|         22|        4|              4|\n",
            "|         22|        5|              4|\n",
            "|         37|     NULL|             64|\n",
            "|         37|        1|              5|\n",
            "|         37|        2|             59|\n",
            "|         41|     NULL|              2|\n",
            "|         41|        2|              2|\n",
            "|         48|     NULL|              3|\n",
            "|         48|        1|              1|\n",
            "|         48|        2|              2|\n",
            "|         53|     NULL|              2|\n",
            "|         53|        1|              2|\n",
            "|         56|     NULL|              5|\n",
            "|         56|        1|              5|\n",
            "|         57|     NULL|             10|\n",
            "|         57|        2|             10|\n",
            "|         61|     NULL|              1|\n",
            "|         61|        1|              1|\n",
            "|         63|     NULL|             53|\n",
            "|         63|        1|             25|\n",
            "|         63|        2|             28|\n",
            "|         68|     NULL|              4|\n",
            "|         68|        1|              2|\n",
            "|         68|        2|              2|\n",
            "|         70|     NULL|             52|\n",
            "|         70|        2|             52|\n",
            "|         71|     NULL|              2|\n",
            "|         71|        2|              2|\n",
            "|         73|     NULL|              2|\n",
            "|         73|        1|              1|\n",
            "|         73|        2|              1|\n",
            "|         75|     NULL|              2|\n",
            "|         75|        1|              1|\n",
            "|         75|        2|              1|\n",
            "|         77|     NULL|              6|\n",
            "|         77|        1|              2|\n",
            "|         77|        2|              4|\n",
            "|         79|     NULL|              5|\n",
            "|         79|        1|              4|\n",
            "|         79|        2|              1|\n",
            "|         82|     NULL|              6|\n",
            "|         82|        1|              2|\n",
            "|         82|        2|              4|\n",
            "|         85|     NULL|              2|\n",
            "|         85|        1|              1|\n",
            "|         85|        2|              1|\n",
            "|         87|     NULL|              6|\n",
            "|         87|        2|              6|\n",
            "|         88|     NULL|              4|\n",
            "|         88|        1|              2|\n",
            "|         88|        2|              2|\n",
            "|         91|     NULL|              1|\n",
            "|         91|        1|              1|\n",
            "|         95|     NULL|             34|\n",
            "|         95|        1|              5|\n",
            "|         95|        2|             29|\n",
            "|         98|     NULL|              7|\n",
            "|         98|        2|              7|\n",
            "|         99|     NULL|              2|\n",
            "|         99|        1|              2|\n",
            "|        103|     NULL|              1|\n",
            "+-----------+---------+---------------+\n",
            "only showing top 100 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# # DataFrame with the number of posts per user and 'Question' post type\n",
        "# Null fields are aggregation fields. For example:\n",
        "# null null = all posts\n",
        "# null 1    = all post of type 1\n",
        "# 4    null = all posts from user with id 4\n",
        "# 4    1    = all posts of type 1 from user with id 4\n",
        "# NOTE: disregard posts with types 4 and 5.\n",
        "dfPostPerUserAndType = groupByUserAndPostType.count()\n",
        "dfPostPerUserAndType.printSchema()\n",
        "dfPostPerUserAndType.select(colUserId.alias(\"User number\"),\n",
        "                             colPostType.alias(\"Post type\"),\n",
        "                             colNPosts.alias(\"Number of posts\"))\\\n",
        "                     .orderBy(colUserId,colPostType)\\\n",
        "                     .show(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaTiWe8AgMRe"
      },
      "source": [
        "## Joins\n",
        "Spark offers the possibility of performing multiple types of joins (as in SQL)\n",
        "\n",
        "  - inner, outer, left outer, right outer, left semi, left anti, cross"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wotj0yOHgN8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785611fb-8762-4c99-ed60-fd9a95b90031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of questions with an accepted reply = 222\n",
            "Number of replies = 765\n"
          ]
        }
      ],
      "source": [
        "# We want to join each question that has an accepted reply with the actual reply chosen as the accepted answer\n",
        "# We join the colAcceptedReplyId field from the questions with the id field from the answers\n",
        "dfQuestions = dfQuestionWithAcceptedReply\\\n",
        "                .select(colUserId, colBody, colAcceptedReplyId)\\\n",
        "                .withColumnRenamed(\"userId\", \"User question\")\\\n",
        "                .withColumnRenamed(\"body\", \"Question\")\\\n",
        "                .withColumnRenamed(\"acceptedAnswerId\", \"ID Accepted Reply\")\n",
        "\n",
        "colId = col(\"id\")\n",
        "dfReplies = dfSE\\\n",
        "                .select(colId, colUserId, colBody)\\\n",
        "                .where(colPostType == 2)\\\n",
        "                .withColumnRenamed(\"id\", \"ID Reply\")\\\n",
        "                .withColumnRenamed(\"userId\", \"User reply\")\\\n",
        "                .withColumnRenamed(\"body\", \"Reply\")\n",
        "\n",
        "nQuestions = dfQuestions.count()\n",
        "nReplies = dfReplies.count()\n",
        "print(\"Number of questions with an accepted reply = {0}\".format(nQuestions))\n",
        "print(\"Number of replies = {0}\".format(nReplies))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F53DitxIVijS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2996f62e-6887-4af7-c2fb-4e047f97c532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------------------+-----------------+\n",
            "|User question|            Question|ID Accepted Reply|\n",
            "+-------------+--------------------+-----------------+\n",
            "|          154|&lt;p&gt;As part ...|             1170|\n",
            "|           63|&lt;p&gt;When I w...|             1181|\n",
            "|           63|&lt;p&gt;Suppose ...|             1177|\n",
            "|           63|&lt;p&gt;Except w...|             1182|\n",
            "|           63|&lt;p&gt;Comparin...|             1180|\n",
            "|           22|&lt;p&gt;Many peo...|             1263|\n",
            "|          159|&lt;p&gt;Sono un'...|             1185|\n",
            "|            8|&lt;p&gt;The use ...|             1212|\n",
            "|           17|&lt;p&gt;When wri...|             1195|\n",
            "|           63|&lt;p&gt;When wri...|             1202|\n",
            "|           99|&lt;p&gt;I can't ...|             1216|\n",
            "|           63|&lt;p&gt;Some wor...|             1207|\n",
            "|           63|&lt;p&gt;In Lomba...|             1226|\n",
            "|           63|&lt;p&gt;The plur...|             1227|\n",
            "|           63|&lt;p&gt;I rememb...|             1223|\n",
            "|           99|&lt;p&gt;Is it ma...|             1228|\n",
            "|          132|&lt;p&gt;I always...|             1235|\n",
            "|           18|&lt;p&gt;Where do...|             1230|\n",
            "|           53|&lt;p&gt;Do all I...|             1234|\n",
            "|          159|&lt;p&gt;Girando ...|             1247|\n",
            "+-------------+--------------------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+--------+----------+--------------------+\n",
            "|ID Reply|User reply|               Reply|\n",
            "+--------+----------+--------------------+\n",
            "|    1165|        17|&lt;p&gt;The infi...|\n",
            "|    1167|        17|&lt;p&gt;Il verbo...|\n",
            "|    1169|        70|&lt;p&gt;&lt;em&g...|\n",
            "|    1170|        17|&lt;p&gt;There's ...|\n",
            "|    1171|        63|&lt;p&gt;As other...|\n",
            "|    1172|        63|&lt;p&gt;The expr...|\n",
            "|    1174|        18|&lt;p&gt;Wow, wha...|\n",
            "|    1177|        71|&lt;p&gt;Both you...|\n",
            "|    1178|        12|&lt;blockquote&gt...|\n",
            "|    1180|        18|&lt;p&gt;Using th...|\n",
            "|    1181|       132|&lt;p&gt;I would ...|\n",
            "|    1182|       132|&lt;p&gt;Putting ...|\n",
            "|    1185|        17|&lt;p&gt;Una velo...|\n",
            "|    1186|        37|&lt;p&gt;Il &lt;e...|\n",
            "|    1188|        17|&lt;p&gt;È un'esp...|\n",
            "|    1190|        17|&lt;p&gt;Because ...|\n",
            "|    1191|         8|&lt;p&gt;It's an ...|\n",
            "|    1194|        12|&lt;p&gt;Comma + ...|\n",
            "|    1195|       132|&lt;p&gt;Although...|\n",
            "|    1196|         8|&lt;p&gt;&lt;stro...|\n",
            "+--------+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dfQuestions.show()\n",
        "dfReplies.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NX8OeXkugjid",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "073e0ab2-20ac-4747-b94f-f62a76b3bb4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column<'(ID Accepted Reply = ID Reply)'>\n"
          ]
        }
      ],
      "source": [
        "# Join expression\n",
        "joinExpression = dfQuestions[\"ID Accepted Reply\"] == dfReplies[\"ID Reply\"]\n",
        "print(joinExpression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtLpashygmtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ace4672f-9b36-4d5f-ea5c-a013499c0f30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows = 222\n",
            "+-------------+--------------------+-----------------+--------+----------+--------------------+\n",
            "|User question|            Question|ID Accepted Reply|ID Reply|User reply|               Reply|\n",
            "+-------------+--------------------+-----------------+--------+----------+--------------------+\n",
            "|          154|&lt;p&gt;As part ...|             1170|    1170|        17|&lt;p&gt;There's ...|\n",
            "|           63|&lt;p&gt;Suppose ...|             1177|    1177|        71|&lt;p&gt;Both you...|\n",
            "|           63|&lt;p&gt;Comparin...|             1180|    1180|        18|&lt;p&gt;Using th...|\n",
            "|           63|&lt;p&gt;When I w...|             1181|    1181|       132|&lt;p&gt;I would ...|\n",
            "|           63|&lt;p&gt;Except w...|             1182|    1182|       132|&lt;p&gt;Putting ...|\n",
            "|          159|&lt;p&gt;Sono un'...|             1185|    1185|        17|&lt;p&gt;Una velo...|\n",
            "|           17|&lt;p&gt;When wri...|             1195|    1195|       132|&lt;p&gt;Although...|\n",
            "|           63|&lt;p&gt;When wri...|             1202|    1202|         8|&lt;p&gt;Same as ...|\n",
            "|           63|&lt;p&gt;Some wor...|             1207|    1207|        37|&lt;p&gt;A rule o...|\n",
            "|            8|&lt;p&gt;The use ...|             1212|    1212|        70|&lt;p&gt;The etym...|\n",
            "|           99|&lt;p&gt;I can't ...|             1216|    1216|        63|&lt;p&gt;Lo Zinga...|\n",
            "|           63|&lt;p&gt;I rememb...|             1223|    1223|       132|&lt;p&gt;I've hea...|\n",
            "|           63|&lt;p&gt;In Lomba...|             1226|    1226|        70|&lt;p&gt;It's use...|\n",
            "|           63|&lt;p&gt;The plur...|             1227|    1227|        82|&lt;p&gt;As far a...|\n",
            "|           99|&lt;p&gt;Is it ma...|             1228|    1228|        82|&lt;p&gt;No, in g...|\n",
            "|           18|&lt;p&gt;Where do...|             1230|    1230|         8|&lt;p&gt;&lt;a hr...|\n",
            "|           53|&lt;p&gt;Do all I...|             1234|    1234|        22|&lt;p&gt;Adjectiv...|\n",
            "|          132|&lt;p&gt;I always...|             1235|    1235|        17|&lt;p&gt;I'm afra...|\n",
            "|          159|&lt;p&gt;Girando ...|             1247|    1247|        19|&lt;p&gt;Il sito ...|\n",
            "|           68|&lt;p&gt;Some adj...|             1256|    1256|         8|&lt;p&gt;Yes, Ita...|\n",
            "|           22|&lt;p&gt;Many peo...|             1263|    1263|         8|&lt;p&gt;If we fo...|\n",
            "|           79|&lt;p&gt;Alle ele...|             1271|    1271|         8|&lt;p&gt;Il tuo i...|\n",
            "|           63|&lt;p&gt;In Itali...|             1277|    1277|        70|&lt;p&gt;&lt;em&g...|\n",
            "|          176|&lt;p&gt;In Engli...|             1286|    1286|        37|&lt;p&gt;Traditio...|\n",
            "|           22|&lt;p&gt;Standard...|             1293|    1293|        37|&lt;p&gt;Very sho...|\n",
            "|           85|&lt;p&gt;Take a l...|             1317|    1317|        37|&lt;p&gt;Accordin...|\n",
            "|          114|&lt;p&gt;There ar...|             1330|    1330|        70|&lt;p&gt;I agree ...|\n",
            "|            8|&lt;p&gt;Wikipedi...|             1336|    1336|       189|&lt;p&gt;We can d...|\n",
            "|           12|&lt;ol&gt;&lt;li&...|             1337|    1337|       189|&lt;p&gt;Both OK,...|\n",
            "|           22|&lt;p&gt;La parol...|             1338|    1338|       189|&lt;p&gt;Easy: a ...|\n",
            "|           56|&lt;p&gt;The word...|             1344|    1344|        22|&lt;p&gt;It's sim...|\n",
            "|          132|&lt;p&gt;It would...|             1348|    1348|       204|&lt;p&gt;This mig...|\n",
            "|          204|&lt;p&gt;I've bee...|             1351|    1351|        17|&lt;p&gt;First of...|\n",
            "|           12|&lt;p&gt;English ...|             1354|    1354|         8|&lt;p&gt;All Ital...|\n",
            "|            8|&lt;p&gt;Imagine ...|             1377|    1377|       193|&lt;p&gt;«Ridere ...|\n",
            "|           22|&lt;p&gt;The numb...|             1379|    1379|       193|&lt;p&gt;I think ...|\n",
            "|          223|&lt;p&gt;Sto scri...|             1384|    1384|       176|&lt;p&gt;Penso ch...|\n",
            "|          219|&lt;p&gt;Perché n...|             1387|    1387|        37|&lt;p&gt;Such phr...|\n",
            "|          223|&lt;p&gt;Non ries...|             1391|    1391|        17|&lt;p&gt;Quando i...|\n",
            "|           12|&lt;p&gt;Ci sono ...|             1399|    1399|        98|&lt;p&gt;Si potre...|\n",
            "|           12|&lt;p&gt;From the...|             1401|    1401|        68|&lt;p&gt;&lt;stro...|\n",
            "|           22|&lt;p&gt;Ho solo ...|             1408|    1408|        19|&lt;p&gt;Quando g...|\n",
            "|           22|&lt;p&gt;Sostanti...|             1411|    1411|        77|&lt;p&gt;Stai par...|\n",
            "|           12|&lt;p&gt;C'è una ...|             1422|    1422|       193|&lt;p&gt;Treccani...|\n",
            "|          223|&lt;p&gt;Quali so...|             1423|    1423|        18|&lt;p&gt;L'abbrev...|\n",
            "|          158|&lt;p&gt;What is ...|             1435|    1435|       193|&lt;p&gt;&quot;Di...|\n",
            "|           12|&lt;blockquote&gt...|             1439|    1439|         5|&lt;p&gt;&lt;em&g...|\n",
            "|           22|&lt;p&gt;Se vogli...|             1449|    1449|       193|&lt;p&gt;&quot;Se...|\n",
            "|          204|&lt;p&gt;I'm a li...|             1454|    1454|         8|&lt;p&gt;First, &...|\n",
            "|           12|&lt;p&gt;&lt;a hr...|             1459|    1459|        70|&lt;p&gt;I don't ...|\n",
            "|          133|&lt;p&gt;I unders...|             1465|    1465|        70|&lt;p&gt;The unst...|\n",
            "|           12|&lt;p&gt;Certe vo...|             1468|    1468|         8|&lt;p&gt;In realt...|\n",
            "|          217|&lt;p&gt;I'm inte...|             1471|    1471|        57|&lt;p&gt;Sardinia...|\n",
            "|          281|&lt;p&gt;It is so...|             1480|    1480|        70|&lt;p&gt;Your imp...|\n",
            "|          281|&lt;p&gt;I notice...|             1482|    1482|       279|&lt;p&gt;&quot;Ta...|\n",
            "|          281|&lt;p&gt;I come f...|             1488|    1488|        70|&lt;p&gt;That &lt...|\n",
            "|          281|&lt;p&gt;What's t...|             1490|    1490|        37|&lt;p&gt;Yes, it ...|\n",
            "|          281|&lt;p&gt;My conve...|             1496|    1496|        22|&lt;p&gt;Your fri...|\n",
            "|          281|&lt;p&gt;I know f...|             1500|    1500|        22|&lt;p&gt;As for t...|\n",
            "|          281|&lt;p&gt;I know t...|             1507|    1507|       279|&lt;p&gt;Please n...|\n",
            "|          281|&lt;p&gt;As a for...|             1511|    1511|       223|&lt;p&gt;As egreg...|\n",
            "|          295|&lt;p&gt;I know s...|             1516|    1516|        37|&lt;p&gt;It is a ...|\n",
            "|           82|&lt;p&gt;I can't ...|             1517|    1517|       193|&lt;p&gt;Here is ...|\n",
            "|          229|&lt;p&gt;It's cle...|             1523|    1523|       193|&lt;p&gt;Lots of ...|\n",
            "|          281|&lt;p&gt;I always...|             1529|    1529|        70|&lt;p&gt;There ar...|\n",
            "|          193|&lt;p&gt;Let's co...|             1530|    1530|       281|&lt;p&gt;I found ...|\n",
            "|          281|&lt;p&gt;How come...|             1532|    1532|        57|&lt;p&gt;Not ever...|\n",
            "|          281|&lt;p&gt;I heard ...|             1534|    1534|        70|&lt;p&gt;In the p...|\n",
            "|           12|&lt;p&gt;Non so s...|             1540|    1540|       213|&lt;p&gt;&quot;Nu...|\n",
            "|          223|&lt;p&gt;È possib...|             1542|    1542|        37|&lt;p&gt;Bice Mor...|\n",
            "|          145|&lt;p&gt;Is there...|             1544|    1544|       300|&lt;p&gt;The verb...|\n",
            "|           63|&lt;p&gt;When utt...|             1551|    1551|        22|&lt;blockquote&gt...|\n",
            "|          134|&lt;p&gt;Is there...|             1566|    1566|        37|&lt;p&gt;Yes, the...|\n",
            "|          348|&lt;p&gt;Are ther...|             1570|    1570|        18|&lt;p&gt;RAI has ...|\n",
            "|           53|&lt;p&gt;I am uns...|             1577|    1577|        70|&lt;p&gt;The cons...|\n",
            "|          281|&lt;p&gt;I notice...|             1581|    1581|       193|&lt;p&gt;The use ...|\n",
            "|          121|&lt;p&gt;Does any...|             1583|    1583|       223|&lt;p&gt;Probably...|\n",
            "|           63|&lt;p&gt;What is ...|             1596|    1596|        18|&lt;p&gt;The past...|\n",
            "|           63|&lt;p&gt;I am try...|             1601|    1601|       189|&lt;p&gt;Easy sol...|\n",
            "|           63|&lt;p&gt;I am try...|             1603|    1603|       193|&lt;p&gt;The sent...|\n",
            "|           12|&lt;p&gt;In Emili...|             1617|    1617|        70|&lt;p&gt;A giudic...|\n",
            "|           12|&lt;p&gt;Tito Boe...|             1626|    1626|       193|&lt;p&gt;The adje...|\n",
            "|          139|&lt;p&gt;Qual è l...|             1639|    1639|       223|&lt;p&gt;Era un s...|\n",
            "|          281|&lt;p&gt;I someti...|             1658|    1658|       223|&lt;p&gt;There is...|\n",
            "|          193|&lt;p&gt;When par...|             1682|    1682|        37|&lt;p&gt;The basi...|\n",
            "|          425|&lt;p&gt;A friend...|             1692|    1692|        37|&lt;p&gt;I am not...|\n",
            "|          437|&lt;p&gt;What is ...|             1706|    1706|       193|&lt;p&gt;I think ...|\n",
            "|          437|&lt;p&gt;What is ...|             1707|    1707|       193|&lt;p&gt;In this ...|\n",
            "|           12|&lt;p&gt;Just saw...|             1710|    1710|       440|&lt;p&gt;I think ...|\n",
            "|           61|&lt;p&gt;A textbo...|             1713|    1713|        37|&lt;p&gt;La mucca...|\n",
            "|           12|&lt;p&gt;Noto una...|             1715|    1715|       193|&lt;p&gt;I believ...|\n",
            "|          438|&lt;p&gt;L'altro ...|             1720|    1720|        37|&lt;p&gt;Avevo po...|\n",
            "|           91|&lt;p&gt;I rememb...|             1744|    1744|       193|&lt;p&gt;&quot;A ...|\n",
            "|          193|&lt;p&gt;What is ...|             1747|    1747|         8|&lt;p&gt;I would ...|\n",
            "|           12|&lt;p&gt;Secondo ...|             1800|    1800|       445|&lt;p&gt;Alle sue...|\n",
            "|          219|&lt;p&gt;Nel libr...|             1816|    1816|       421|&lt;p&gt;&lt;em&g...|\n",
            "|          805|&lt;p&gt;Qual è i...|             2171|    2171|       591|&lt;p&gt;&lt;a hr...|\n",
            "|          193|&lt;p&gt;Qualcuno...|             2178|    2178|         8|&lt;p&gt;Secondo ...|\n",
            "|          707|&lt;p&gt;Qual è l...|             2183|    2183|       591|&lt;p&gt;In gener...|\n",
            "|          232|&lt;p&gt;Mi chied...|             2185|    2185|       808|&lt;p&gt;La spieg...|\n",
            "|          804|&lt;p&gt;On Sicil...|             2240|    2240|       812|&lt;p&gt;A very w...|\n",
            "|          707|&lt;p&gt;La crisi...|             2242|    2242|       808|&lt;p&gt;&lt;em&g...|\n",
            "|          813|&lt;p&gt;Recently...|             2245|    2245|       193|&lt;p&gt;&quot;Ma...|\n",
            "|          707|&lt;p&gt;Nel roma...|             2246|    2246|       808|&lt;p&gt;Il brano...|\n",
            "|           56|&lt;p&gt;Simple q...|             2249|    2249|       224|&lt;p&gt;While &l...|\n",
            "|          785|&lt;p&gt;I have s...|             2256|    2256|        37|&lt;p&gt;There is...|\n",
            "|          707|&lt;p&gt;Ho letto...|             2260|    2260|       589|&lt;p&gt;Credo ch...|\n",
            "|          785|&lt;p&gt;I am a b...|             2262|    2262|       193|&lt;blockquote&gt...|\n",
            "|          707|&lt;p&gt;Leggendo...|             2264|    2264|       589|&lt;p&gt;L'espres...|\n",
            "|          707|&lt;p&gt;Nel roma...|             2270|    2270|       193|&lt;p&gt;Un &lt;a...|\n",
            "|          833|&lt;p&gt;What doe...|             2277|    2277|       591|&lt;p&gt;If I und...|\n",
            "|          835|&lt;p&gt;I'm sear...|             2280|    2280|        70|&lt;p&gt;The &lt;...|\n",
            "|          707|&lt;p&gt;When try...|             2288|    2288|       193|&lt;p&gt;In the s...|\n",
            "|          845|&lt;p&gt;In conve...|             2290|    2290|       193|&lt;p&gt;The noun...|\n",
            "|          707|&lt;p&gt;Ho un du...|             2295|    2295|        37|&lt;p&gt;“Consult...|\n",
            "|          855|&lt;p&gt;For a li...|             2298|    2298|       707|&lt;p&gt;You can ...|\n",
            "|          707|&lt;p&gt;In alcun...|             2302|    2302|         8|&lt;p&gt;Dal &lt;...|\n",
            "|          525|&lt;p&gt;Durante ...|             2303|    2303|       519|&lt;p&gt;Fare il ...|\n",
            "|          785|&lt;p&gt;I wish t...|             2308|    2308|       525|&lt;p&gt;A generi...|\n",
            "|          707|&lt;p&gt;Qual è l...|             2311|    2311|        37|&lt;p&gt;Sono amm...|\n",
            "|           22|&lt;p&gt;I due ve...|             2312|    2312|       519|&lt;p&gt;L'etimol...|\n",
            "|           37|&lt;p&gt;Nel test...|             2313|    2313|       193|&lt;p&gt;Secondo ...|\n",
            "|          707|&lt;p&gt;Non sono...|             2316|    2316|       572|&lt;p&gt;Poiché i...|\n",
            "|          707|&lt;p&gt;C'è qual...|             2320|    2320|       193|&lt;p&gt;La doman...|\n",
            "|          707|&lt;p&gt;Questa d...|             2324|    2324|       193|&lt;p&gt;Indipend...|\n",
            "|          707|&lt;p&gt;Ho letto...|             2326|    2326|       801|&lt;p&gt;Sì, puoi...|\n",
            "|          785|&lt;p&gt;In Engli...|             2333|    2333|        22|&lt;p&gt;As far a...|\n",
            "|          591|&lt;p&gt;Nel parl...|             2336|    2336|       808|&lt;p&gt;Martire,...|\n",
            "|          707|&lt;p&gt;Sapresti...|             2340|    2340|       519|&lt;p&gt;Secondo ...|\n",
            "|          523|&lt;p&gt;After li...|             2342|    2342|       707|&lt;p&gt;It's a r...|\n",
            "|          707|&lt;p&gt;Ho osser...|             2344|    2344|        37|&lt;p&gt;Prima di...|\n",
            "|            8|&lt;p&gt;What is ...|                2|       2|        17|&lt;p&gt;Translat...|\n",
            "|           18|&lt;p&gt;When an ...|                8|       8|         6|&lt;p&gt;While th...|\n",
            "|           17|&lt;p&gt;I often ...|               12|      12|        22|&lt;p&gt;Grammati...|\n",
            "|           37|&lt;p&gt;Are ther...|               20|      20|         8|&lt;p&gt;From the...|\n",
            "|           12|&lt;p&gt;How does...|               25|      25|        17|&lt;p&gt;In my op...|\n",
            "|           56|&lt;p&gt;I know t...|               30|      30|        17|&lt;p&gt;&lt;em&g...|\n",
            "|           48|&lt;p&gt;A common...|               36|      36|        37|&lt;p&gt;In Itali...|\n",
            "|           79|&lt;p&gt;Posto ch...|               40|      40|        77|&lt;p&gt;This que...|\n",
            "|           88|&lt;p&gt;What is ...|               45|      45|        18|&lt;p&gt;They are...|\n",
            "|           88|&lt;p&gt;Sometime...|               52|      52|        85|&lt;p&gt;Everytim...|\n",
            "|           56|&lt;p&gt;I have r...|               55|      55|        95|&lt;p&gt;With a p...|\n",
            "|           63|&lt;p&gt;Are &lt;...|               60|      60|        98|&lt;p&gt;&lt;em&g...|\n",
            "|           63|&lt;p&gt;In Ameri...|               61|      61|        37|&lt;p&gt;In the s...|\n",
            "|          114|&lt;p&gt;Is the p...|               77|      77|         8|&lt;p&gt;No, plur...|\n",
            "|          120|&lt;p&gt;I've not...|               83|      83|        98|&lt;p&gt;When tal...|\n",
            "|           56|&lt;p&gt;My dicti...|               84|      84|        63|&lt;p&gt;It means...|\n",
            "|          124|&lt;p&gt;When do ...|               88|      88|         8|&lt;p&gt;Yes, the...|\n",
            "|           12|&lt;blockquote&gt...|               93|      93|        17|&lt;p&gt;I'd tran...|\n",
            "|           63|&lt;p&gt;In Engli...|              101|     101|         5|&lt;p&gt;Just as ...|\n",
            "|           63|&lt;p&gt;Can I us...|              102|     102|        17|&lt;p&gt;English ...|\n",
            "|           17|&lt;p&gt;I often ...|              106|     106|        63|&lt;p&gt;Capitali...|\n",
            "|           63|&lt;p&gt;In Ameri...|              113|     113|       124|&lt;p&gt;Simple r...|\n",
            "|           63|&lt;p&gt;A phrase...|              117|     117|        37|&lt;p&gt;There is...|\n",
            "|           63|&lt;p&gt;When tra...|              120|     120|        37|&lt;p&gt;“Sei sta...|\n",
            "|           63|&lt;p&gt;In Engli...|              137|     137|        18|&lt;p&gt;The gene...|\n",
            "|           63|&lt;p&gt;In Engli...|              140|     140|        87|&lt;p&gt;Usually ...|\n",
            "|           63|&lt;p&gt;Is it ac...|              142|     142|        17|&lt;p&gt;Conjunct...|\n",
            "|           63|&lt;p&gt;In Engli...|              143|     143|        70|&lt;p&gt;In the p...|\n",
            "|           12|&lt;p&gt;Yes, as ...|             1150|    1150|         8|&lt;p&gt;Both are...|\n",
            "|           22|&lt;p&gt;Ogni lin...|             1158|    1158|        57|&lt;p&gt;Innanzit...|\n",
            "|          320|&lt;p&gt;I was re...|             1822|    1822|        37|&lt;p&gt;It is an...|\n",
            "|          509|&lt;p&gt;How does...|             1829|    1829|         8|&lt;p&gt;It depen...|\n",
            "|          519|&lt;p&gt;Could a ...|             1834|    1834|       497|&lt;p&gt;Comparin...|\n",
            "|          523|&lt;p&gt;In Engli...|             1838|    1838|        95|&lt;p&gt;in the f...|\n",
            "|          193|&lt;p&gt;Qual è l...|             1853|    1853|       445|&lt;p&gt;Io sugge...|\n",
            "|          320|&lt;p&gt;Is there...|             1858|    1858|       497|&lt;p&gt;As you c...|\n",
            "|          523|&lt;p&gt;Which ve...|             1862|    1862|        37|&lt;p&gt;In the s...|\n",
            "|          523|&lt;p&gt;What is ...|             1869|    1869|       224|&lt;p&gt;This is ...|\n",
            "|           12|&lt;p&gt;Perché s...|             1876|    1876|        70|&lt;p&gt;Non è l'...|\n",
            "|          569|&lt;p&gt;I've com...|             1878|    1878|        70|&lt;p&gt;It's an ...|\n",
            "|          523|&lt;p&gt;I know t...|             1882|    1882|        37|&lt;p&gt;Let me c...|\n",
            "|           12|&lt;blockquote&gt...|             1888|    1888|       421|&lt;p&gt;Corretto...|\n",
            "|          585|&lt;p&gt;Se devo ...|             1895|    1895|        37|&lt;p&gt;Premesso...|\n",
            "|           12|&lt;p&gt;Sento fr...|             1902|    1902|       591|&lt;p&gt;&lt;em&g...|\n",
            "|          523|&lt;p&gt;What is ...|             1905|    1905|       193|&lt;p&gt;&quot;Co...|\n",
            "|          523|&lt;p&gt;Is there...|             1917|    1917|        37|&lt;p&gt;&lt;em&g...|\n",
            "|          523|&lt;p&gt;When do ...|             1922|    1922|       193|&lt;p&gt;&quot;Se...|\n",
            "|          407|&lt;p&gt;In frasi...|             1927|    1927|       606|&lt;p&gt;Partendo...|\n",
            "|          608|&lt;p&gt;L'ho vis...|             1943|    1943|       193|&lt;p&gt;Se la &l...|\n",
            "|          623|&lt;p&gt;I'm just...|             1950|    1950|        37|&lt;p&gt;No poeti...|\n",
            "|          523|&lt;p&gt;Recently...|             1955|    1955|       193|&lt;p&gt;&quot;&l...|\n",
            "|          523|&lt;p&gt;Do we sa...|             1961|    1961|       193|&lt;p&gt;Both can...|\n",
            "|          523|&lt;p&gt;When I w...|             1965|    1965|        70|&lt;p&gt;In the e...|\n",
            "|           22|&lt;p&gt;In itali...|             1968|    1968|       193|&lt;p&gt;&quot;&l...|\n",
            "|          608|&lt;p&gt;I know t...|             1973|    1973|       193|&lt;p&gt;&quot;Ta...|\n",
            "|          523|&lt;p&gt;I lost m...|             1979|    1979|       645|&lt;p&gt;The prop...|\n",
            "|          663|&lt;p&gt;In a sen...|             1987|    1987|       659|&lt;p&gt;Your poi...|\n",
            "|          145|&lt;p&gt;I'm wond...|             1993|    1993|        22|&lt;p&gt;It'd be ...|\n",
            "|          145|&lt;p&gt;Can some...|             1994|    1994|        22|&lt;p&gt;Your con...|\n",
            "|          523|&lt;p&gt;Besides ...|             1997|    1997|        95|&lt;p&gt;From &lt...|\n",
            "|          235|&lt;p&gt;Mi ricor...|             2004|    2004|        70|&lt;p&gt;In itali...|\n",
            "|          223|&lt;p&gt;Mi è sta...|             2006|    2006|        37|&lt;p&gt;“Ca.” è ...|\n",
            "|           95|&lt;p&gt;Ecco una...|             2010|    2010|       677|&lt;p&gt;In some ...|\n",
            "|          679|&lt;p&gt;I don't ...|             2012|    2012|       193|&lt;p&gt;In Itali...|\n",
            "|          683|&lt;p&gt;Si tratt...|             2016|    2016|       193|&lt;p&gt;Il cugin...|\n",
            "|          145|&lt;p&gt;A friend...|             2025|    2025|       703|&lt;p&gt;Idroscal...|\n",
            "|          707|&lt;p&gt;Ho trova...|             2031|    2031|       193|&lt;p&gt;Secondo ...|\n",
            "|          707|&lt;p&gt;Conosco ...|             2035|    2035|       193|&lt;p&gt;&quot;&l...|\n",
            "|          707|&lt;p&gt;Frequent...|             2037|    2037|        22|&lt;p&gt;&lt;em&g...|\n",
            "|          707|&lt;p&gt;Non ries...|             2039|    2039|       193|&lt;p&gt;Sono int...|\n",
            "|          707|&lt;p&gt;Ho letto...|             2045|    2045|       224|&lt;p&gt;Secondo ...|\n",
            "|          707|&lt;p&gt;Immagino...|             2049|    2049|       714|&lt;p&gt;Si dice ...|\n",
            "|          707|&lt;p&gt;Ho letto...|             2054|    2054|        37|&lt;p&gt;Il signi...|\n",
            "|          707|&lt;p&gt;La mia d...|             2059|    2059|        70|&lt;p&gt;La mia i...|\n",
            "|          749|&lt;p&gt;My girlf...|             2089|    2089|         5|&lt;p&gt;Maybe yo...|\n",
            "|          749|&lt;p&gt;Is there...|             2096|    2096|        18|&lt;p&gt;The rule...|\n",
            "|          707|&lt;p&gt;Leggendo...|             2102|    2102|       224|&lt;p&gt;Il nome ...|\n",
            "|          707|&lt;p&gt;So che l...|             2105|    2105|       589|&lt;p&gt;La diffe...|\n",
            "|          764|&lt;p&gt;I'm tryi...|             2113|    2113|       589|&lt;p&gt;&lt;em&g...|\n",
            "|          519|&lt;p&gt;What is ...|             2117|    2117|       589|&lt;p&gt;No, it p...|\n",
            "|          768|&lt;p&gt;Se una c...|             2120|    2120|       193|&lt;p&gt;Entrambe...|\n",
            "|          567|&lt;p&gt;Why do I...|             2122|    2122|       519|&lt;p&gt;I think ...|\n",
            "|           22|&lt;p&gt;Qualcuno...|             2132|    2132|       193|&lt;p&gt;&quot;&l...|\n",
            "|          765|&lt;p&gt;Alcune p...|             2134|    2134|       193|&lt;p&gt;Ciò dipe...|\n",
            "|          776|&lt;p&gt;Da dove ...|             2137|    2137|       193|&lt;p&gt;Spero di...|\n",
            "|          725|&lt;blockquote&gt...|             2139|    2139|       193|&lt;p&gt;Il tuo è...|\n",
            "|          785|&lt;p&gt;In Engli...|             2141|    2141|         5|&lt;p&gt;Not real...|\n",
            "|          785|&lt;p&gt;I write ...|             2144|    2144|       193|&lt;p&gt;A medica...|\n",
            "|          785|&lt;p&gt;In a blo...|             2146|    2146|       193|&lt;p&gt;&lt;a hr...|\n",
            "|          591|&lt;p&gt;In occas...|             2158|    2158|       193|&lt;p&gt;Mettendo...|\n",
            "|          785|&lt;p&gt;I have d...|             2162|    2162|       591|&lt;p&gt;There is...|\n",
            "+-------------+--------------------+-----------------+--------+----------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Inner join\n",
        "# Include only rows for which the joinExpression is true\n",
        "joinType = \"inner\"\n",
        "dfInner = dfQuestions.join(dfReplies, joinExpression, joinType)\n",
        "nRows = dfInner.count()\n",
        "print(\"Number of rows = {0}\".format(nRows))\n",
        "dfInner.show(nRows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V340E9Gagpge"
      },
      "outputs": [],
      "source": [
        "# Outer join\n",
        "# Include all rows from both DataFrames.\n",
        "# In the case there are no matching values on any of the DataFrames, give a null value.\n",
        "joinType = \"outer\"\n",
        "dfOuter = dfQuestions.join(dfReplies, joinExpression, joinType)\n",
        "nRows = dfOuter.count()\n",
        "print(\"Number of rows = {0}\".format(nRows))\n",
        "dfOuter.show(nRows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjz9xalggrcI"
      },
      "outputs": [],
      "source": [
        "# Left Outer join\n",
        "# Include all rows from the left DataFrame (first DataFrame)\n",
        "# If there are no matching values on the right DataFrame, give a null value.\n",
        "joinType = \"left_outer\"\n",
        "dfLOuter = dfQuestions.join(dfReplies, joinExpression, joinType)\n",
        "nRows = dfLOuter.count()\n",
        "print(\"Number of rows = {0}\".format(nRows))\n",
        "dfLOuter.show(nRows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcJe0BegguEk"
      },
      "outputs": [],
      "source": [
        "# Right Outer join\n",
        "# Include all rows from the right DataFrame (second DataFrame)\n",
        "# If there are no matching values on the left DataFrame, give a null value.\n",
        "joinType = \"right_outer\"\n",
        "dfROuter = dfQuestions.join(dfReplies, joinExpression, joinType)\n",
        "nRows = dfROuter.count()\n",
        "print(\"Number of rows = {0}\".format(nRows))\n",
        "dfROuter.show(nRows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsnCeQGggwAB"
      },
      "outputs": [],
      "source": [
        "# Left Semi join\n",
        "# The result includes all values from the first DataFrame that also exist in the second one.\n",
        "joinType = \"left_semi\"\n",
        "dfLSemi = dfReplies.join(dfQuestions, joinExpression, joinType)\n",
        "nRows = dfLSemi.count()\n",
        "print(\"Number of rows = {0}\".format(nRows))\n",
        "dfLSemi.show(nRows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9yzBSTBgyRE"
      },
      "outputs": [],
      "source": [
        "# Left Anti join\n",
        "# The result includes all values from the first DataFrame that DO NOT exist in the second one.\n",
        "joinType = \"left_anti\"\n",
        "dfLAnti = dfReplies.join(dfQuestions, joinExpression, joinType)\n",
        "nRows = dfLAnti.count()\n",
        "print(\"Number of rows = {0}\".format(nRows))\n",
        "dfLAnti.show(nRows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZxEhZ7ig0X1"
      },
      "outputs": [],
      "source": [
        "# Cross join\n",
        "# Cartesian product, joins each row from the first DataFrame with all rows from the second one.\n",
        "# IT IS STRONGLY ADVISED NOT TO USE IT, BECAUSE IT IS EXTREMELY COSTLY\n",
        "dfCross = dfReplies.crossJoin(dfQuestions)\n",
        "nRows = dfCross.count()\n",
        "print(\"Number of rows = {0}\".format(nRows))\n",
        "dfCross.show(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_ay9hNAJZzo"
      },
      "source": [
        "## Scalar functions and aggregations\n",
        "\n",
        "Spark has a wide offer of functions to operate with DataFrames:\n",
        "- Mathematical functions: ``abs``, ``log``, ``hypot``, etc.\n",
        "- Operations with strings: ``lenght``, ``concat``, etc.\n",
        "- Operations with dates: ``year``, ``date_add``, etc.\n",
        "- Aggregation operations: ``min``, ``max``, ``count``, ``avg``, ``sum``, ``sumDistinct``, ``stddev``, ``variance``, ``kurtosis``, ``skewness``, ``first``, ``last``, ``window``, etc.\n",
        "\n",
        "A detailed description of those functions can be found on  https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjuscCLLNMM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "848bfb12-daaa-47df-8d1f-05c7dc8bb63c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The question \n",
            "\n",
            "<p>The plural of <em>braccio</em> is <em>braccia</em>, and the plural of <em>avambraccio</em> is <em>avambracci</em>.</p><p>Why are the plural of those words so different, if they both are referring to parts of the human body, and <em>avambraccio</em> derives from <em>braccio</em>?</p>\n",
            "\n",
            "has been active 303 days\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import datediff, col\n",
        "colLastActivity = col(\"lastActivity\")\n",
        "colCreationDate = col(\"Date_of_creation\")\n",
        "\n",
        "# Search for the question with an accepted answer that was active the longest time\n",
        "# (i.e. with the highest difference between the LastActivity -\"lastActivity\"- and Creation_date)\n",
        "\n",
        "mostActive = dfQuestionWithAcceptedReply.withColumn(\"ActiveTime\",datediff(colLastActivity,colCreationDate))\\\n",
        "            .orderBy(\"ActiveTime\", ascending=False)\\\n",
        "            .head()\n",
        "\n",
        "print(\"The question \\n\\n{0}\\n\\nhas been active {1} days\".\\\n",
        "      format(mostActive.body.replace(\"&lt;\", \"<\").replace(\"&gt;\", \">\"), mostActive.ActiveTime))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLyOnKhmNRBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc8294ed-05f3-4d3b-ee49-36345535ae37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------------------------------------+-----+\n",
            "|userId|Week                                      |count|\n",
            "+------+------------------------------------------+-----+\n",
            "|63    |{2013-11-07 00:00:00, 2013-11-14 00:00:00}|18   |\n",
            "|281   |{2013-12-12 00:00:00, 2013-12-19 00:00:00}|8    |\n",
            "|707   |{2014-09-04 00:00:00, 2014-09-11 00:00:00}|5    |\n",
            "|707   |{2014-06-26 00:00:00, 2014-07-03 00:00:00}|5    |\n",
            "|707   |{2014-07-03 00:00:00, 2014-07-10 00:00:00}|4    |\n",
            "|707   |{2014-08-21 00:00:00, 2014-08-28 00:00:00}|3    |\n",
            "|281   |{2013-12-19 00:00:00, 2013-12-26 00:00:00}|3    |\n",
            "|707   |{2014-08-28 00:00:00, 2014-09-04 00:00:00}|3    |\n",
            "|785   |{2014-07-31 00:00:00, 2014-08-07 00:00:00}|3    |\n",
            "|523   |{2014-04-17 00:00:00, 2014-04-24 00:00:00}|3    |\n",
            "|12    |{2013-11-21 00:00:00, 2013-11-28 00:00:00}|3    |\n",
            "|63    |{2014-01-16 00:00:00, 2014-01-23 00:00:00}|3    |\n",
            "|12    |{2013-11-07 00:00:00, 2013-11-14 00:00:00}|2    |\n",
            "|12    |{2013-11-28 00:00:00, 2013-12-05 00:00:00}|2    |\n",
            "|22    |{2013-11-14 00:00:00, 2013-11-21 00:00:00}|2    |\n",
            "|56    |{2013-10-31 00:00:00, 2013-11-07 00:00:00}|2    |\n",
            "|88    |{2013-10-31 00:00:00, 2013-11-07 00:00:00}|2    |\n",
            "|99    |{2013-11-07 00:00:00, 2013-11-14 00:00:00}|2    |\n",
            "|707   |{2014-09-11 00:00:00, 2014-09-18 00:00:00}|2    |\n",
            "|223   |{2013-11-21 00:00:00, 2013-11-28 00:00:00}|2    |\n",
            "+------+------------------------------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import window\n",
        "# Obtain the number of posts per week from each user\n",
        "# Group by userId and a date-of-creation window of one week\n",
        "dfQuestionWithAcceptedReply.groupBy(\n",
        "                   colUserId, window(colCreationDate, \"1 week\").alias(\"Week\"))\\\n",
        "                  .count()\\\n",
        "                  .sort(\"count\", ascending=False)\\\n",
        "                  .show(20,False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mp82ZMrgNTyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4358032e-e282-415e-b2d3-bf087b6fea0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----------+------------+\n",
            "|       avg(score)|max(score)|count(score)|\n",
            "+-----------------+----------+------------+\n",
            "|4.159397303727201|        24|        1261|\n",
            "+-----------------+----------+------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "# Search the average and maximum of the \"points\" (score) of all rows as well as the total number in the DataFrame\n",
        "dfSE.select(F.avg(colPoints), F.max(colPoints), F.count(colPoints)).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6utH2VnNWqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1d3356c-c611-43f5-d455-a53c3072e918"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|summary|             score|\n",
            "+-------+------------------+\n",
            "|  count|              1261|\n",
            "|   mean| 4.159397303727201|\n",
            "| stddev|3.7147241498508063|\n",
            "|    min|                -3|\n",
            "|    max|                24|\n",
            "+-------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Again, but using 'describe'\n",
        "dfSE.select(colPoints).describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxVgR2PuNY2p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "24b74ab7-4bb9-4d3f-ceca-7ed4cc88fe99"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Score histogram\n",
        "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
        "import matplotlib.pyplot as plt\n",
        "#from io import StringIO\n",
        "import io\n",
        "\n",
        "def show(p):\n",
        "    img = io.StringIO()\n",
        "    p.savefig(img, format='svg')\n",
        "    img.seek(0)\n",
        "#    print (\"%html <div style='width:600px'>\" + img.buf() + \"</div>\")\n",
        "\n",
        "# Obtain a histogram with 10 groups\n",
        "x,y = dfSE.select(colPoints).rdd.flatMap(lambda x:x).histogram(20)\n",
        "\n",
        "# Clean the graph\n",
        "plt.gcf().clear()\n",
        "\n",
        "plt.bar(x[:-1], y, width=1.3)\n",
        "plt.xlabel(u'Score')\n",
        "plt.ylabel(u'Number of occurrences')\n",
        "plt.title(u'Histogram')\n",
        "\n",
        "show(plt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErAk3pekNcBU"
      },
      "source": [
        "\n",
        "## Complex types\n",
        "\n",
        "Spark works with three types of complex data: `structs`, `arrays` and `maps`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz4pgmWvNe03"
      },
      "source": [
        "### Structs\n",
        "\n",
        "DataFrames inside DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YT5udaEnNiCq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba5527d9-1920-4713-a297-760bb8cbbe28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+--------+--------------+\n",
            "|  id|numViewed|nAnswers|Viewed_Replied|\n",
            "+----+---------+--------+--------------+\n",
            "|1165|        0|       0|        {0, 0}|\n",
            "|1166|       61|       1|       {61, 1}|\n",
            "|1167|        0|       0|        {0, 0}|\n",
            "|1168|      187|       4|      {187, 4}|\n",
            "|1169|        0|       0|        {0, 0}|\n",
            "+----+---------+--------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import struct\n",
        "# Create a new DF with a column that combines two existing columns\n",
        "colNumViews = col(\"numViewed\")\n",
        "colNReplies = col(\"nAnswers\")\n",
        "dfStruct = dfSE.select(colId, colNumViews, colNReplies, struct(colNumViews, colNReplies)\\\n",
        "               .alias(\"Viewed_Replied\"))\n",
        "dfStruct.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUOdIc7MNnBc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43bce53c-85fa-4029-cc5f-e54a55ce7a9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------+\n",
            "|Viewed_Replied.numViewed|\n",
            "+------------------------+\n",
            "|                       0|\n",
            "|                      61|\n",
            "|                       0|\n",
            "|                     187|\n",
            "|                       0|\n",
            "+------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Obtain a field of the combined column\n",
        "dfStruct.select(col(\"Viewed_Replied\").getField(\"numViewed\")).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTmdbtBFNpN_"
      },
      "source": [
        "\n",
        "### Arrays\n",
        "\n",
        "Arrays let us work with data as if they were a Python array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlSjiUj1Nun6"
      },
      "source": [
        "*Example*\n",
        "\n",
        "Obtain the number of *tags* for each question with an accepted reply and replace the ``&lt;`` and ``&gt;`` by  ''<'' and ''>''\n",
        "\n",
        "  - \"tags\" from each question are saved in a concatenated way, separated by   ''<'' and ''>'', codified as ``&lt;`` and ``&gt;``\n",
        "\n",
        "`&lt;english-comparison&gt;&lt;translation&gt;&lt;phrase-request&gt;`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yG2BVeJLNwKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc1a959e-02b0-457f-c24f-abfbf62ece5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|nComs|        lastActivity|userId|                body|score|       Creation_date|numViewed|               title|                tags|nAnswers|acceptedAnswerId|postType|  id|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|    4|2013-11-11 18:21:...|    17|&lt;p&gt;The infi...|   23|2013-11-10 19:37:...|        0|                NULL|                NULL|       0|            NULL|       2|1165|\n",
            "|    5|2013-11-10 20:31:...|    12|&lt;p&gt;Come cre...|    1|2013-11-10 19:44:...|       61|Cosa sapreste dir...| &lt;word-choice&gt;|       1|            NULL|       1|1166|\n",
            "|    2|2013-11-10 20:31:...|    17|&lt;p&gt;Il verbo...|    5|2013-11-10 19:58:...|        0|                NULL|                NULL|       0|            NULL|       2|1167|\n",
            "|    1|2014-07-25 13:15:...|   154|&lt;p&gt;As part ...|   11|2013-11-10 22:03:...|      187|Ironic constructi...|&lt;english-compa...|       4|            1170|       1|1168|\n",
            "|    0|2013-11-10 22:15:...|    70|&lt;p&gt;&lt;em&g...|    3|2013-11-10 22:15:...|        0|                NULL|                NULL|       0|            NULL|       2|1169|\n",
            "|    2|2013-11-10 22:17:...|    17|&lt;p&gt;There's ...|    8|2013-11-10 22:17:...|        0|                NULL|                NULL|       0|            NULL|       2|1170|\n",
            "|    1|2013-11-11 09:51:...|    63|&lt;p&gt;As other...|    3|2013-11-11 09:51:...|        0|                NULL|                NULL|       0|            NULL|       2|1171|\n",
            "|    1|2013-11-12 23:57:...|    63|&lt;p&gt;The expr...|    1|2013-11-11 10:09:...|        0|                NULL|                NULL|       0|            NULL|       2|1172|\n",
            "|    9|2014-01-05 11:13:...|    63|&lt;p&gt;When I w...|    5|2013-11-11 10:28:...|      122|Is &quot;scancell...|&lt;usage&gt;&lt;...|       3|            1181|       1|1173|\n",
            "|    0|2013-11-11 10:58:...|    18|&lt;p&gt;Wow, wha...|    5|2013-11-11 10:58:...|        0|                NULL|                NULL|       0|            NULL|       2|1174|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "only showing top 10 rows\n",
            "\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|nComs|        lastActivity|userId|                body|score|       Creation_date|numViewed|               title|                tags|nAnswers|acceptedAnswerId|postType|  id|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|    5|2013-11-10 20:31:...|    12|&lt;p&gt;Come cre...|    1|2013-11-10 19:44:...|       61|Cosa sapreste dir...| &lt;word-choice&gt;|       1|            NULL|       1|1166|\n",
            "|    1|2014-07-25 13:15:...|   154|&lt;p&gt;As part ...|   11|2013-11-10 22:03:...|      187|Ironic constructi...|&lt;english-compa...|       4|            1170|       1|1168|\n",
            "|    9|2014-01-05 11:13:...|    63|&lt;p&gt;When I w...|    5|2013-11-11 10:28:...|      122|Is &quot;scancell...|&lt;usage&gt;&lt;...|       3|            1181|       1|1173|\n",
            "|    1|2014-01-16 19:56:...|    63|&lt;p&gt;Suppose ...|    4|2013-11-11 11:31:...|      114|How should I tran...|&lt;usage&gt;&lt;...|       2|            1177|       1|1175|\n",
            "|    0|2013-11-11 14:36:...|    63|&lt;p&gt;Except w...|    3|2013-11-11 11:39:...|       58|Using a comma bet...|&lt;usage&gt;&lt;...|       2|            1182|       1|1176|\n",
            "|    0|2013-11-12 11:24:...|    63|&lt;p&gt;Comparin...|    3|2013-11-11 12:58:...|       60|Using the conditi...|&lt;usage&gt;&lt;...|       2|            1180|       1|1179|\n",
            "|    2|2013-11-14 09:56:...|    22|&lt;p&gt;Many peo...|    6|2013-11-11 14:43:...|      321|Can Dante Alighie...|&lt;history&gt;&l...|       1|            1263|       1|1183|\n",
            "|    2|2013-11-11 23:23:...|   159|&lt;p&gt;Sono un'...|    7|2013-11-11 18:19:...|      138|origine dell'espr...|&lt;idioms&gt;&lt...|       2|            1185|       1|1184|\n",
            "|    2|2014-08-19 15:39:...|    12|&lt;p&gt;Quando s...|    4|2013-11-11 18:52:...|      149|Sapreste dirmi pe...|&lt;idioms&gt;&lt...|       2|            NULL|       1|1187|\n",
            "|    0|2013-11-11 21:44:...|    12|&lt;p&gt;Why do I...|    8|2013-11-11 20:13:...|      387|Why do Italians r...|     &lt;grammar&gt;|       2|            NULL|       1|1189|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# First, obtain a DataFrame without null tags\n",
        "dfSE.show(10)\n",
        "dfNotNullTags = dfSE.dropna(\"any\", subset=[\"tags\"])\n",
        "dfNotNullTags.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssk_TYD1Nzhn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12e2c2d8-de49-4c38-cbd3-9efc891414b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------+---------------------------------------------------------+\n",
            "|tags                                                               |tag_array                                                |\n",
            "+-------------------------------------------------------------------+---------------------------------------------------------+\n",
            "|&lt;word-choice&gt;                                                |[&lt;word-choice&gt;]                                    |\n",
            "|&lt;english-comparison&gt;&lt;translation&gt;&lt;phrase-request&gt;|[&lt;english-comparison, translation, phrase-request&gt;]|\n",
            "|&lt;usage&gt;&lt;verbs&gt;                                         |[&lt;usage, verbs&gt;]                                   |\n",
            "|&lt;usage&gt;&lt;tenses&gt;&lt;english-comparison&gt;              |[&lt;usage, tenses, english-comparison&gt;]              |\n",
            "|&lt;usage&gt;&lt;punctuation&gt;                                   |[&lt;usage, punctuation&gt;]                             |\n",
            "|&lt;usage&gt;&lt;tenses&gt;                                        |[&lt;usage, tenses&gt;]                                  |\n",
            "|&lt;history&gt;&lt;english-comparison&gt;                          |[&lt;history, english-comparison&gt;]                    |\n",
            "|&lt;idioms&gt;&lt;etymology&gt;                                    |[&lt;idioms, etymology&gt;]                              |\n",
            "|&lt;idioms&gt;&lt;regional&gt;                                     |[&lt;idioms, regional&gt;]                               |\n",
            "|&lt;grammar&gt;                                                    |[&lt;grammar&gt;]                                        |\n",
            "+-------------------------------------------------------------------+---------------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Add a column with all tags splitted\n",
        "from pyspark.sql.functions import split\n",
        "colTags = col(\"tags\")\n",
        "dfTags = dfNotNullTags.withColumn(\"tag_array\", split(colTags, \"&gt;&lt;\"))\n",
        "dfTags.select(colTags, col(\"tag_array\")).show(10, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78q1cSyKN1o4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e054923-305d-40ea-b12a-8d3808628eb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------+---------------+\n",
            "|tag_array                                                |size(tag_array)|\n",
            "+---------------------------------------------------------+---------------+\n",
            "|[&lt;word-choice&gt;]                                    |1              |\n",
            "|[&lt;english-comparison, translation, phrase-request&gt;]|3              |\n",
            "|[&lt;usage, verbs&gt;]                                   |2              |\n",
            "|[&lt;usage, tenses, english-comparison&gt;]              |3              |\n",
            "|[&lt;usage, punctuation&gt;]                             |2              |\n",
            "+---------------------------------------------------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import size\n",
        "# Show the number of tags of each entry\n",
        "colTag_array = col(\"tag_array\")\n",
        "dfTags.select(colTag_array, size(colTag_array)).show(5, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYVIOWIkN4KS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd41d3dc-e3a8-47c0-c0db-397e6ec56e24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------+---------------+\n",
            "|tag_array                                                |tag_array[1]   |\n",
            "+---------------------------------------------------------+---------------+\n",
            "|[&lt;word-choice&gt;]                                    |NULL           |\n",
            "|[&lt;english-comparison, translation, phrase-request&gt;]|translation    |\n",
            "|[&lt;usage, verbs&gt;]                                   |verbs&gt;      |\n",
            "|[&lt;usage, tenses, english-comparison&gt;]              |tenses         |\n",
            "|[&lt;usage, punctuation&gt;]                             |punctuation&gt;|\n",
            "+---------------------------------------------------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show the second tag of each entry\n",
        "dfTags.selectExpr(\"tag_array\", \"tag_array[1]\").show(5, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2Anu7EMN6ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8415f28b-efd6-455a-97df-ce66b3f308d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------+----------+\n",
            "|tag_array                                                |With_usage|\n",
            "+---------------------------------------------------------+----------+\n",
            "|[&lt;word-choice&gt;]                                    |false     |\n",
            "|[&lt;english-comparison, translation, phrase-request&gt;]|false     |\n",
            "|[&lt;usage, verbs&gt;]                                   |true      |\n",
            "|[&lt;usage, tenses, english-comparison&gt;]              |true      |\n",
            "|[&lt;usage, punctuation&gt;]                             |true      |\n",
            "+---------------------------------------------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import array_contains\n",
        "# Look up whether the word \"usage\" appears in the tags\n",
        "dfTags.withColumn(\"With_usage\", array_contains(colTag_array, \"&lt;usage\"))\\\n",
        "      .select(colTag_array, col(\"With_usage\")).show(5, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijiJfn6kN8FR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3881b8c2-524b-48e0-c6e0-04000a34e000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------+----------------------+\n",
            "|tags                                                               |Tags2                 |\n",
            "+-------------------------------------------------------------------+----------------------+\n",
            "|&lt;word-choice&gt;                                                |&lt;word-choice&gt;   |\n",
            "|&lt;english-comparison&gt;&lt;translation&gt;&lt;phrase-request&gt;|&lt;english-comparison|\n",
            "|&lt;english-comparison&gt;&lt;translation&gt;&lt;phrase-request&gt;|translation           |\n",
            "|&lt;english-comparison&gt;&lt;translation&gt;&lt;phrase-request&gt;|phrase-request&gt;    |\n",
            "|&lt;usage&gt;&lt;verbs&gt;                                         |&lt;usage             |\n",
            "|&lt;usage&gt;&lt;verbs&gt;                                         |verbs&gt;             |\n",
            "|&lt;usage&gt;&lt;tenses&gt;&lt;english-comparison&gt;              |&lt;usage             |\n",
            "|&lt;usage&gt;&lt;tenses&gt;&lt;english-comparison&gt;              |tenses                |\n",
            "|&lt;usage&gt;&lt;tenses&gt;&lt;english-comparison&gt;              |english-comparison&gt;|\n",
            "|&lt;usage&gt;&lt;punctuation&gt;                                   |&lt;usage             |\n",
            "+-------------------------------------------------------------------+----------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import explode\n",
        "# Convert each tag in a row\n",
        "dfTagsRows = dfTags.withColumn(\"Tags2\", explode(colTag_array))\n",
        "dfTagsRows.select(colTags, col(\"Tags2\")).show(10, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNayzA52N9kf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71aa8bb4-1df5-4ca1-8161-df3441ca5c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------+------------------+\n",
            "|tags                                                               |Tags_splitted     |\n",
            "+-------------------------------------------------------------------+------------------+\n",
            "|&lt;word-choice&gt;                                                |word-choice       |\n",
            "|&lt;english-comparison&gt;&lt;translation&gt;&lt;phrase-request&gt;|english-comparison|\n",
            "|&lt;english-comparison&gt;&lt;translation&gt;&lt;phrase-request&gt;|translation       |\n",
            "|&lt;english-comparison&gt;&lt;translation&gt;&lt;phrase-request&gt;|phrase-request    |\n",
            "|&lt;usage&gt;&lt;verbs&gt;                                         |usage             |\n",
            "|&lt;usage&gt;&lt;verbs&gt;                                         |verbs             |\n",
            "|&lt;usage&gt;&lt;tenses&gt;&lt;english-comparison&gt;              |usage             |\n",
            "|&lt;usage&gt;&lt;tenses&gt;&lt;english-comparison&gt;              |tenses            |\n",
            "|&lt;usage&gt;&lt;tenses&gt;&lt;english-comparison&gt;              |english-comparison|\n",
            "|&lt;usage&gt;&lt;punctuation&gt;                                   |usage             |\n",
            "+-------------------------------------------------------------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Remove symbols &lt; y &gt;\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "dfTags = dfTagsRows.withColumn(\"Tags_splitted\", regexp_replace(\"Tags2\", \"&[l,g]t;\", \"\"))\\\n",
        "                   .drop(\"Tags2\")\n",
        "dfTags.select(colTags, col(\"Tags_splitted\")).show(10, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8ryfwuPN_vX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bffc5ad-e09f-4c34-eeed-5c7953d845cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries with the word-choice tag = 57\n"
          ]
        }
      ],
      "source": [
        "# Number of entries with the \"word-choice\" tag\n",
        "print(\"Number of entries with the word-choice tag = {0}\"\n",
        "      .format(dfTags\n",
        "      .filter(col(\"Tags_splitted\") == \"word-choice\")\n",
        "      .count()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0__r_uLjOB5P"
      },
      "source": [
        "### Maps\n",
        "\n",
        "They are created from columns that work as key-value pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmWw5prXOD2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e1e6139-916d-4134-c408-37954a0e2d6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------+\n",
            "|Dates                                               |\n",
            "+----------------------------------------------------+\n",
            "|{2013-11-10 19:37:54.187 -> 2013-11-11 18:21:10.903}|\n",
            "|{2013-11-10 19:44:53.797 -> 2013-11-10 20:31:00.177}|\n",
            "|{2013-11-10 19:58:02.1 -> 2013-11-10 20:31:00.177}  |\n",
            "|{2013-11-10 22:03:41.027 -> 2014-07-25 13:15:02.27} |\n",
            "|{2013-11-10 22:15:17.693 -> 2013-11-10 22:15:17.693}|\n",
            "+----------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import create_map\n",
        "# Create a column with a key-value map\n",
        "# key: id, value: body\n",
        "dfMap = dfSE.select(create_map(col(\"Creation_date\"), col(\"lastActivity\"))\\\n",
        "            .alias(\"Dates\"))\n",
        "dfMap.show(5, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iI6JeDpOGGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34e67ad6-fe7b-41ec-9930-c1dd19178855"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------+\n",
            "|Dates[2013-11-10 19:58:02.1]|\n",
            "+----------------------------+\n",
            "|NULL                        |\n",
            "|NULL                        |\n",
            "|2013-11-10 20:31:00.177     |\n",
            "|NULL                        |\n",
            "|NULL                        |\n",
            "+----------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We can conduct a search using the key\n",
        "dfMap.selectExpr(\"Dates['2013-11-10 19:58:02.1']\").show(5, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqiaEK7DOIh4"
      },
      "source": [
        "## Window functions\n",
        "\n",
        "Similar to aggregation functions, they operate in groups of rows, returning a single value for each row. This allows, among others:\n",
        "\n",
        "  - To obtain moving averages\n",
        "  - To calculate cumulative sums\n",
        "  - To access values higher than the current row value\n",
        "\n",
        "Basically, a window function calculates a value for each input row from a table based on a group of rows, called *frame*.\n",
        "\n",
        "As window functions we can use the aggregation functions previously seen as well as other additional functions (``cume_dist``, ``dense_rank``, ``lag``, ``lead``, ``ntile``, ``percent_rank``, ``rank``, ``row_number``) specified as *Window function* in https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsNLqnIkOL3R"
      },
      "source": [
        "#### Example 1\n",
        "From the ``dfQuestionWithAcceptedReply`` DataFrame, show the score (column \"points\") maximum per user and for each question, the difference between the question score and the user's maximum score.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8JpMFbQOOSb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3e97ee-1998-4c89-8492-d06fad3e144b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.window.WindowSpec'>\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Specify the windows to partition the rows by the userId column\n",
        "window = Window.partitionBy(colUserId)\n",
        "print(type(window))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPT2WYuYOQd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7f69861-0d1a-489e-d155-2a1614a568f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.column.Column'>\n"
          ]
        }
      ],
      "source": [
        "# Create a column with the maximum score per user\n",
        "colMaxPoints = F.max(colPoints).over(window)\n",
        "print(type(colMaxPoints))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "471ky0FnOUnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "820abe65-ef8d-426a-b53b-caeb46ed1d79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+-----+----------+----------+\n",
            "|userId|Question|score|maxPerUser|Difference|\n",
            "+------+--------+-----+----------+----------+\n",
            "|     8|       1|   20|        20|         0|\n",
            "|     8|    1192|   13|        20|         7|\n",
            "|     8|    1321|   10|        20|        10|\n",
            "|     8|    1365|    3|        20|        17|\n",
            "|    12|      19|    2|        10|         8|\n",
            "|    12|      89|    4|        10|         6|\n",
            "|    12|    1146|    1|        10|         9|\n",
            "|    12|    1329|    2|        10|         8|\n",
            "|    12|    1352|    5|        10|         5|\n",
            "|    12|    1398|    2|        10|         8|\n",
            "|    12|    1400|    1|        10|         9|\n",
            "|    12|    1420|    0|        10|        10|\n",
            "|    12|    1437|    1|        10|         9|\n",
            "|    12|    1452|   -2|        10|        12|\n",
            "|    12|    1466|   10|        10|         0|\n",
            "|    12|    1535|    3|        10|         7|\n",
            "|    12|    1612|    4|        10|         6|\n",
            "|    12|    1621|    5|        10|         5|\n",
            "|    12|    1662|    0|        10|        10|\n",
            "|    12|    1714|    7|        10|         3|\n",
            "|    12|    1799|    7|        10|         3|\n",
            "|    12|    1875|    4|        10|         6|\n",
            "|    12|    1887|    3|        10|         7|\n",
            "|    12|    1900|    2|        10|         8|\n",
            "|    17|      10|   10|        10|         0|\n",
            "|    17|     103|    6|        10|         4|\n",
            "|    17|    1193|    5|        10|         5|\n",
            "|    18|       6|   10|        10|         0|\n",
            "|    18|    1229|    5|        10|         5|\n",
            "|    22|     136|    3|        12|         9|\n",
            "+------+--------+-----+----------+----------+\n",
            "only showing top 30 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Obtain a new DataFrame including the maximum score per user and the difference\n",
        "# between this maximum and each question score\n",
        "dfQuestionWithAcceptedReply.select(colUserId, colId.alias(\"Question\"),\n",
        "                          colPoints, colMaxPoints.alias(\"maxPerUser\"))\\\n",
        "                  .withColumn(\"Difference\", colMaxPoints-colPoints)\\\n",
        "                  .orderBy(colUserId, colId)\\\n",
        "                  .show(30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzj45bl2OXlS"
      },
      "source": [
        "#### Example 2\n",
        "Show for each user and question from the ``dfQuestionWithAcceptedReply`` DataFrame  the number of days spent between the previous user question until the current one, and from the current one to the following one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UisxHyv4OZib"
      },
      "outputs": [],
      "source": [
        "# Specify the window to partition the rows by the userId column and sort them by creation day\n",
        "window = Window.partitionBy(colUserId).orderBy(colCreationDate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VwWdogcOghH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc0bbf4e-945a-4c10-f705-3c219822e93c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+-----------------------+---------+----------+\n",
            "|userId|id  |Creation Date          |Days from|Days until|\n",
            "+------+----+-----------------------+---------+----------+\n",
            "|8     |1   |2013-11-05 20:22:07.323|NULL     |6         |\n",
            "|8     |1192|2013-11-11 21:01:13.34 |6        |9         |\n",
            "|8     |1321|2013-11-20 16:42:19.91 |9        |3         |\n",
            "|8     |1365|2013-11-23 09:09:04.993|3        |NULL      |\n",
            "|12    |19  |2013-11-05 22:38:26.767|NULL     |2         |\n",
            "|12    |89  |2013-11-07 19:22:45.923|2        |2         |\n",
            "|12    |1146|2013-11-09 21:24:03.593|2        |11        |\n",
            "|12    |1329|2013-11-20 22:20:58.87 |11       |2         |\n",
            "|12    |1352|2013-11-22 08:08:34.063|2        |4         |\n",
            "|12    |1398|2013-11-26 20:08:13.423|4        |1         |\n",
            "|12    |1400|2013-11-27 08:05:11.63 |1        |2         |\n",
            "|12    |1420|2013-11-29 21:15:01.09 |2        |2         |\n",
            "|12    |1437|2013-12-01 18:11:27.07 |2        |6         |\n",
            "|12    |1452|2013-12-07 22:04:57.82 |6        |2         |\n",
            "|12    |1466|2013-12-09 20:57:37.927|2        |11        |\n",
            "|12    |1535|2013-12-20 21:47:06.63 |11       |29        |\n",
            "|12    |1612|2014-01-18 22:32:31.31 |29       |3         |\n",
            "|12    |1621|2014-01-21 03:22:12.383|3        |12        |\n",
            "|12    |1662|2014-02-02 21:06:38.383|12       |19        |\n",
            "|12    |1714|2014-02-21 21:03:47.297|19       |13        |\n",
            "|12    |1799|2014-03-06 19:51:16.093|13       |34        |\n",
            "|12    |1875|2014-04-09 20:30:00.823|34       |6         |\n",
            "|12    |1887|2014-04-15 03:15:28.18 |6        |4         |\n",
            "|12    |1900|2014-04-19 20:08:30.87 |4        |NULL      |\n",
            "|17    |10  |2013-11-05 21:29:03.997|NULL     |2         |\n",
            "|17    |103 |2013-11-07 23:07:19.077|2        |4         |\n",
            "|17    |1193|2013-11-11 21:01:47.523|4        |NULL      |\n",
            "|18    |6   |2013-11-05 21:01:56.857|NULL     |7         |\n",
            "|18    |1229|2013-11-12 14:49:07.607|7        |NULL      |\n",
            "|22    |136 |2013-11-09 10:45:01.437|NULL     |2         |\n",
            "+------+----+-----------------------+---------+----------+\n",
            "only showing top 30 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a column to reference the previous question (in date)\n",
        "PreviousCol = F.lag(colCreationDate, 1).over(window)\n",
        "# Create a column to reference the following question (in date)\n",
        "FollowingCol = F.lead(colCreationDate, 1).over(window)\n",
        "\n",
        "# Show for each user and question the id of the previous and following questions\n",
        "dfQuestionWithAcceptedReply.select(colUserId, colId, colCreationDate.alias(\"Creation Date\"),\n",
        "                          F.datediff(colCreationDate,PreviousCol).alias(\"Days from\"),\n",
        "                          F.datediff(FollowingCol,colCreationDate).alias(\"Days until\"))\\\n",
        "                  .orderBy(colUserId, colId)\\\n",
        "                  .show(30, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn8Wpc4GO4XE"
      },
      "source": [
        "## User-Defined Functions (UDFs)\n",
        "\n",
        "If we need a function that is not implemented, we can create our own function to operate on columns.\n",
        "\n",
        "**Note:**\n",
        "  - UDFs in Python may be quite inefficient, due to the data serialisation in Python\n",
        "  - It is recommended to code them in Scala or Java (and then call them from Python)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUDo_inWO7s_"
      },
      "source": [
        "#### Example\n",
        "\n",
        "User UDFs to obtain the number of *tags* for each question and change the ``&lt;`` and ``&gt;`` by  ''<'' and ''>''\n",
        "\n",
        "  - The \"tags\" from each question are stored concatenated, separated by  ''<'' and ''>'', and coded as ``&lt;`` and ``&gt;``\n",
        "\n",
        "`&lt;english-comparison&gt;&lt;translation&gt;&lt;phrase-request&gt;`\n",
        "\n",
        "To count the number of tags, it is enough to count the number of times ``&lt;`` appears in the string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3UMYrG9OjEg"
      },
      "outputs": [],
      "source": [
        "colTags = col(\"tags\")\n",
        "# Obtain a DataFrame without null tags\n",
        "dfNoNullTags = dfSE.na.drop(\"any\", subset=[\"tags\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xII8Fn74PETO"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import udf\n",
        "\n",
        "# Define a function that returns the number of &lt; in a string\n",
        "def countTags(tags):\n",
        "    return tags.count('&lt;')\n",
        "\n",
        "# Define a function that replaces &lt and &gt by < and >\n",
        "def replaceTags(tags):\n",
        "    return tags.replace('&lt;', '<').replace('&gt;', '>')\n",
        "\n",
        "# Create udfs from these functions\n",
        "udfCountTags = udf(countTags)\n",
        "udfReplaceTags = udf(replaceTags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP2puRELPPyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e12140-fe17-42ac-9c4f-1822e88dda81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------+-----+\n",
            "|Tags                                             |nTags|\n",
            "+-------------------------------------------------+-----+\n",
            "|<word-choice>                                    |1    |\n",
            "|<english-comparison><translation><phrase-request>|3    |\n",
            "|<usage><verbs>                                   |2    |\n",
            "|<usage><tenses><english-comparison>              |3    |\n",
            "|<usage><punctuation>                             |2    |\n",
            "|<usage><tenses>                                  |2    |\n",
            "|<history><english-comparison>                    |2    |\n",
            "|<idioms><etymology>                              |2    |\n",
            "|<idioms><regional>                               |2    |\n",
            "|<grammar>                                        |1    |\n",
            "|<prepositions><etymology>                        |2    |\n",
            "|<punctuation><list><writing>                     |3    |\n",
            "|<grammar>                                        |1    |\n",
            "|<usage><punctuation><sentences>                  |3    |\n",
            "|<grammar><verbs>                                 |2    |\n",
            "|<nouns><plural><grammatical-number>              |3    |\n",
            "|<grammar><word-meaning>                          |2    |\n",
            "|<grammar>                                        |1    |\n",
            "|<usage><idioms><tenses>                          |3    |\n",
            "|<plural><grammatical-number>                     |2    |\n",
            "+-------------------------------------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dfNoNullTags.select(udfReplaceTags(colTags).alias(\"Tags\"),\\\n",
        "                          udfCountTags(colTags).alias(\"nTags\"))\\\n",
        "                  .show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsxGCSDBI5BZ"
      },
      "source": [
        "**NOTE:** Only Python and Swift are officially supported languages on Colaboratory. If we want to create the UDFs in Scala using Colaboratory, please follow [this instructions](https://medium.com/@shadaj/machine-learning-with-scala-in-google-colaboratory-e6f1661f1c88) to install and configure a Scala kernel. Otherwise, the following two code blocks will not work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l36KWJFKPTBB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "f4eeaf90-8b84-4a42-b9a7-e35de53f1006"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'String' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-bd94a53dca49>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create the previous functions in Scala\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mcountTagsSc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mString\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mInt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"&lt;\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreplaceTagsSc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mString\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mString\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"&lt;\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"<\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"&gt;\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\">\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Register those functions as a Spark SQL function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'String' is not defined"
          ]
        }
      ],
      "source": [
        "# Create the previous functions in Scala\n",
        "def countTagsSc(tags:String):Int = tags.split(\"&lt;\").size - 1\n",
        "def replaceTagsSc(tags:String):String = tags.replace(\"&lt;\", \"<\").replace(\"&gt;\", \">\")\n",
        "\n",
        "# Register those functions as a Spark SQL function\n",
        "spark.udf.register(\"udfCountTagsSc\", lambda x: countTagsSc(x))\n",
        "spark.udf.register(\"udfReplaceTagsSc\", lambda x: replaceTagsSc(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fs1igO7hSGBp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "outputId": "33c3881f-3660-48d8-d8e1-98f086186936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- nComs: integer (nullable = true)\n",
            " |-- lastActivity: timestamp (nullable = true)\n",
            " |-- userId: long (nullable = true)\n",
            " |-- body: string (nullable = true)\n",
            " |-- score: integer (nullable = true)\n",
            " |-- Creation_date: timestamp (nullable = true)\n",
            " |-- numViewed: integer (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- tags: string (nullable = true)\n",
            " |-- nAnswers: integer (nullable = true)\n",
            " |-- acceptedAnswerId: long (nullable = true)\n",
            " |-- postType: byte (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[UNRESOLVED_ROUTINE] Cannot resolve function `udfReplaceTagsSc` on search path [`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`].; line 1 pos 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-5d9d154b85e5>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdfNoNullTags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Call IDFs Scala using an expression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m dfNoNullTags.selectExpr(\"udfReplaceTagsSc(tags) AS Tags\",\n\u001b[0m\u001b[1;32m      4\u001b[0m                               \"udfCountTagsSc(tags) AS nTags\")\\\n\u001b[1;32m      5\u001b[0m                   \u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselectExpr\u001b[0;34m(self, *expr)\u001b[0m\n\u001b[1;32m   3267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3268\u001b[0m             \u001b[0mexpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3269\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselectExpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark/python/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_ROUTINE] Cannot resolve function `udfReplaceTagsSc` on search path [`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`].; line 1 pos 0"
          ]
        }
      ],
      "source": [
        "dfNoNullTags.printSchema()\n",
        "# Call IDFs Scala using an expression\n",
        "dfNoNullTags.selectExpr(\"udfReplaceTagsSc(tags) AS Tags\",\n",
        "                              \"udfCountTagsSc(tags) AS nTags\")\\\n",
        "                  .show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWQYv4ACSJ26"
      },
      "source": [
        "## Using SQL commands\n",
        "\n",
        "SQL commands executed from Spark are converted to operations on DataFrames\n",
        "\n",
        " - It is possible to run remote commands using the JDBC/ODBC server [Thrift](https://spark.apache.org/docs/latest/sql-programming-guide.html#distributed-sql-engine)\n",
        " - It can also work with stored data in [Apache Hive](https://spark.apache.org/docs/latest/sql-programming-guide.html#hive-tables)\n",
        "\n",
        "To use SQL commands on a DataFrame , the DataFrame must be registered as a *table* or *view*.\n",
        "\n",
        " - The view can be created as a temporary one (it is deleted when the session ends) or as a global one (kept between sessions).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34_7b-2GSNUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e7d949-82c3-4938-8b52-9369af8b545e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "# Registers the dfQuestionWithAcceptedReply DataFrame as a temporary view\n",
        "dfQuestionWithAcceptedReply.createOrReplaceTempView(\"table_QuestionWithAcceptedReply\")\n",
        "\n",
        "# Create a table with the data stored in Parquet\n",
        "spark.sql(\"CREATE TABLE table_SE USING PARQUET OPTIONS (path '\"+os.environ[\"DRIVE_DATA\"] + \"dfSE.parquet\" + \"')\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuVJ6wzgSPzd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2206021c-bbe3-4323-fc77-702bb350bc83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- nComs: integer (nullable = true)\n",
            " |-- lastActivity: timestamp (nullable = true)\n",
            " |-- userId: long (nullable = true)\n",
            " |-- body: string (nullable = true)\n",
            " |-- score: integer (nullable = true)\n",
            " |-- Creation_date: timestamp (nullable = true)\n",
            " |-- numViewed: integer (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- tags: string (nullable = true)\n",
            " |-- nAnswers: integer (nullable = true)\n",
            " |-- acceptedAnswerId: long (nullable = true)\n",
            " |-- postType: byte (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"SELECT * FROM table_SE\").printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xJd_XlmSRqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba7ec44-2ba3-404b-a401-4f52ba1e03ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+\n",
            "|userId|  id|\n",
            "+------+----+\n",
            "|   154|1168|\n",
            "|   132|1181|\n",
            "|   132|1182|\n",
            "|   159|1184|\n",
            "|   132|1195|\n",
            "+------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Run a SQL command on the table contents\n",
        "dfUser100 = spark.sql(\"\"\"SELECT userId,id FROM table_SE\n",
        "                         WHERE userId >= 100\"\"\")\n",
        "dfUser100.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AyFArOXST49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60130b6c-6e7a-4e37-99ae-f76753475efa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------------+-----------+\n",
            "|namespace|           tableName|isTemporary|\n",
            "+---------+--------------------+-----------+\n",
            "|  default|            table_se|      false|\n",
            "|         |table_questionwit...|       true|\n",
            "+---------+--------------------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show the created tables\n",
        "spark.sql(\"SHOW TABLES\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SvrtcygSVjj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05caeb68-1ebd-490b-e968-e9ed29dd8f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|nComs|        lastActivity|userId|                body|score|    Date_of_creation|numViewed|               title|                tags|nAnswers|acceptedAnswerId|postType|  id|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "|    1|2014-07-25 13:15:...|   154|&lt;p&gt;As part ...|   11|2013-11-10 22:03:...|      187|Ironic constructi...|&lt;english-compa...|       4|            1170|       1|1168|\n",
            "|    9|2014-01-05 11:13:...|    63|&lt;p&gt;When I w...|    5|2013-11-11 10:28:...|      122|Is &quot;scancell...|&lt;usage&gt;&lt;...|       3|            1181|       1|1173|\n",
            "|    1|2014-01-16 19:56:...|    63|&lt;p&gt;Suppose ...|    4|2013-11-11 11:31:...|      114|How should I tran...|&lt;usage&gt;&lt;...|       2|            1177|       1|1175|\n",
            "|    0|2013-11-11 14:36:...|    63|&lt;p&gt;Except w...|    3|2013-11-11 11:39:...|       58|Using a comma bet...|&lt;usage&gt;&lt;...|       2|            1182|       1|1176|\n",
            "|    0|2013-11-12 11:24:...|    63|&lt;p&gt;Comparin...|    3|2013-11-11 12:58:...|       60|Using the conditi...|&lt;usage&gt;&lt;...|       2|            1180|       1|1179|\n",
            "+-----+--------------------+------+--------------------+-----+--------------------+---------+--------------------+--------------------+--------+----------------+--------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a new DataFrame from one of the tables\n",
        "dfFromTable = spark.sql(\"SELECT * FROM table_QuestionWithAcceptedReply\")\n",
        "dfFromTable.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FusaDLDZSXeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb95db9d-1a54-4ba7-fdef-8d08ff2f6689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+-----------+\n",
            "|namespace|tableName|isTemporary|\n",
            "+---------+---------+-----------+\n",
            "+---------+---------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"DROP TABLE IF EXISTS table_QuestionWithAcceptedReply\")\n",
        "spark.sql(\"DROP TABLE IF EXISTS table_SE\")\n",
        "\n",
        "spark.sql(\"SHOW TABLES\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkJSOev3XOPn"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Exercises\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ppnan-_ELFI"
      },
      "source": [
        "## Exercise 4.1: Pi Estimation\n",
        "\n",
        "Using the Monte Carlo method, estimate the value of Pi. Use the random() method from the random class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSkWxWdJ5Vk8"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With RDD :"
      ],
      "metadata": {
        "id": "V_MnlIAx3Epc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Step 1: Initialize SparkSession\n",
        "spark = SparkSession.builder.appName(\"Pi Estimation\").getOrCreate()\n",
        "\n",
        "# Step 2: Number of points to simulate\n",
        "NUM_POINTS = 1000000\n",
        "\n",
        "# Step 3: Create an RDD with NUM_POINTS random samples\n",
        "rdd = spark.sparkContext.parallelize(range(NUM_POINTS))\n",
        "\n",
        "# Step 4: Function to determine if a point is inside the unit circle\n",
        "def is_inside_unit_circle(_):\n",
        "    x = random.random()\n",
        "    y = random.random()\n",
        "    return x**2 + y**2 <= 1\n",
        "\n",
        "# Step 5: Map points to 1 if inside circle, 0 otherwise\n",
        "points_inside_circle = rdd.map(is_inside_unit_circle).filter(lambda inside: inside == True).count()\n",
        "\n",
        "# Step 6: Calculate Pi\n",
        "pi_estimate = 4 * (points_inside_circle / NUM_POINTS)\n",
        "\n",
        "# Step 7: Output the result\n",
        "print(f\"Estimated value of Pi using {NUM_POINTS} points: {pi_estimate}\")\n",
        "\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5TMjlA5zDL4",
        "outputId": "4d4ea028-9c2f-44f8-f567-bbd66f1a63c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated value of Pi using 1000000 points: 3.141432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With a Dataframe :"
      ],
      "metadata": {
        "id": "3bUa_BvR2_a9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import rand, pow, col\n",
        "\n",
        "# Step 0: Initialize SparkSession\n",
        "spark = SparkSession.builder.appName(\"Pi Estimation\").getOrCreate()\n",
        "\n",
        "# Step 1: Number of points to simulate\n",
        "NUM_POINTS = 1000000  # Increase for more accuracy\n",
        "\n",
        "# Step 2: Create a DataFrame with random x and y points\n",
        "df_points = (\n",
        "    spark.range(NUM_POINTS)\n",
        "    .select(\n",
        "        rand(seed=0).alias(\"x\"),\n",
        "        rand(seed=1).alias(\"y\")\n",
        "    )\n",
        ")\n",
        "\n",
        "# Step 3: Add a column to determine if the point is inside the unit circle\n",
        "df_inside_circle = df_points.withColumn(\n",
        "    \"inside_circle\", (pow(col(\"x\"), 2) + pow(col(\"y\"), 2) <= 1).cast(\"int\")\n",
        ")\n",
        "\n",
        "# Step 4: Count points inside the circle\n",
        "points_inside_circle = df_inside_circle.agg({\"inside_circle\": \"sum\"}).collect()[0][0]\n",
        "\n",
        "# Step 5: Calculate Pi\n",
        "pi_estimate = 4 * (points_inside_circle / NUM_POINTS)\n",
        "\n",
        "# Step 6: Output the result\n",
        "print(f\"Estimated value of Pi using {NUM_POINTS} points: {pi_estimate}\")\n",
        "\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nnpiWGIz_j8",
        "outputId": "acb89a32-cdc1-4ebf-96ee-30b50ad3d9de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated value of Pi using 1000000 points: 3.137908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vPYCnS8ERmg"
      },
      "source": [
        "## Exercise 4.2: Inspect a log file\n",
        "\n",
        "Upload the file /var/log/syslog from your computer to this notebook. Then, select only the \"bad lines\": WARNING and ERROR messages."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "RTo7oJej43Zv",
        "outputId": "dc781fa6-f74c-4126-b406-98ca563d914c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-936a1b49-17b9-47d7-982e-accfff574357\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-936a1b49-17b9-47d7-982e-accfff574357\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving syslog to syslog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Demr8raN4yIx",
        "outputId": "724bb6d1-b9de-4ee3-c7f8-225e382c14be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  syslog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VR-Men-G5ZdZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7262165c-fdf8-49c0-e529-278e6ca524e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bad lines (WARNING and ERROR messages):\n",
            "Nov 25 17:22:07 paul-serin ovpn-cytech.students[1358]: WARNING: file '/data/CYTECH-VPN-CLE-PERSONNELLE/client.p12' is group or others accessible\n",
            "Nov 25 17:22:07 paul-serin ovpn-cytech.students[1358]: WARNING: Your certificate has expired!\n",
            "Nov 25 17:22:07 paul-serin gnome-session[1456]: gnome-session-binary[1456]: WARNING: Falling back to non-systemd startup procedure due to error: GDBus.Error:org.freedesktop.DBus.Error.Spawn.ChildExited: Process org.freedesktop.systemd1 exited with status 1\n",
            "Nov 25 17:22:07 paul-serin gnome-session-binary[1456]: WARNING: Falling back to non-systemd startup procedure due to error: GDBus.Error:org.freedesktop.DBus.Error.Spawn.ChildExited: Process org.freedesktop.systemd1 exited with status 1\n",
            "Nov 25 17:22:15 paul-serin gnome-shell[1481]: JS WARNING: [resource:///org/gnome/shell/ui/layout.js 24]: reference to undefined property \"MetaWindowXwayland\"\n",
            "Nov 25 17:22:21 paul-serin gnome-session[2098]: gnome-session-binary[2098]: WARNING: Could not parse desktop file nautilus-autostart.desktop or it references a not found TryExec binary\n",
            "Nov 25 17:22:21 paul-serin gnome-session-binary[2098]: WARNING: Could not parse desktop file nautilus-autostart.desktop or it references a not found TryExec binary\n",
            "Nov 25 17:22:22 paul-serin ovpn-cytech.students[1358]: WARNING: Your certificate has expired!\n",
            "Nov 25 17:22:29 paul-serin gnome-shell[2515]: [2509:2509:1125/172229.203746:ERROR:object_proxy.cc(576)] Failed to call method: org.freedesktop.ScreenSaver.GetActive: object_path= /org/freedesktop/ScreenSaver: org.freedesktop.DBus.Error.NotSupported: This method is not implemented\n",
            "Nov 25 17:22:32 paul-serin gnome-shell[2515]: [2509:2537:1125/172232.122190:ERROR:registration_request.cc(274)] Registration URL fetching failed.\n",
            "Nov 25 17:22:32 paul-serin gnome-shell[2515]: [2509:2537:1125/172232.122548:ERROR:registration_request.cc(274)] Registration URL fetching failed.\n",
            "Nov 25 17:22:32 paul-serin gnome-shell[2515]: [2509:2537:1125/172232.122613:ERROR:registration_request.cc(274)] Registration URL fetching failed.\n",
            "Nov 25 17:22:32 paul-serin gnome-shell[2515]: [2509:2537:1125/172232.122660:ERROR:registration_request.cc(274)] Registration URL fetching failed.\n",
            "Nov 25 17:22:32 paul-serin gnome-shell[2515]: [2509:2509:1125/172232.852309:ERROR:interface_endpoint_client.cc(725)] Message 1 rejected by interface blink.mojom.WidgetHost\n",
            "Nov 25 17:22:32 paul-serin gnome-shell[2515]: [2509:2509:1125/172232.852532:ERROR:interface_endpoint_client.cc(725)] Message 1 rejected by interface blink.mojom.WidgetHost\n",
            "Nov 25 17:22:37 paul-serin ovpn-cytech.students[1358]: WARNING: Your certificate has expired!\n",
            "Nov 25 17:22:47 paul-serin gnome-shell[2515]: [2509:2509:1125/172247.136366:ERROR:account_info_fetcher.cc(62)] OnGetTokenFailure: Invalid credentials (credentials rejected by server).\n",
            "Nov 25 17:22:52 paul-serin ovpn-cytech.students[1358]: WARNING: Your certificate has expired!\n",
            "Nov 25 17:22:52 paul-serin gnome-shell[2515]: [2509:2537:1125/172252.845564:ERROR:registration_request.cc(291)] Registration response error message: DEPRECATED_ENDPOINT\n",
            "Nov 25 17:23:38 paul-serin gnome-shell[2515]: [2509:2537:1125/172338.434705:ERROR:registration_request.cc(291)] Registration response error message: DEPRECATED_ENDPOINT\n",
            "Nov 25 17:24:09 paul-serin ovpn-cytech.students[1358]: WARNING: Your certificate has expired!\n",
            "Nov 25 17:25:09 paul-serin gnome-shell[2515]: [2509:2537:1125/172509.535766:ERROR:registration_request.cc(291)] Registration response error message: DEPRECATED_ENDPOINT\n",
            "Nov 25 17:25:21 paul-serin discord_discord.desktop[5622]: [5622:1125/172521.737196:ERROR:zygote_host_impl_linux.cc(273)] Failed to adjust OOM score of renderer with pid 5783: Permission denied (13)\n",
            "Nov 25 17:25:22 paul-serin discord_discord.desktop[5810]: [5810:1125/172522.612847:ERROR:ffmpeg_common.cc(965)] Unsupported pixel format: -1\n",
            "Nov 25 17:25:24 paul-serin ovpn-cytech.students[1358]: WARNING: Your certificate has expired!\n",
            "Nov 25 17:25:33 paul-serin discord_discord.desktop[5622]: [5622:1125/172533.292692:ERROR:object_proxy.cc(576)] Failed to call method: org.freedesktop.login1.Manager.Inhibit: object_path= /org/freedesktop/login1: org.freedesktop.DBus.Error.AccessDenied: An AppArmor policy prevents this sender from sending this message to this recipient; type=\"method_call\", sender=\":1.170\" (uid=1000 pid=5622 comm=\"/snap/discord/216/usr/share/discord/Discord --use-\" label=\"snap.discord.discord (enforce)\") interface=\"org.freedesktop.login1.Manager\" member=\"Inhibit\" error name=\"(unset)\" requested_reply=\"0\" destination=\"org.freedesktop.login1\" (uid=0 pid=962 comm=\"/lib/systemd/systemd-logind \" label=\"unconfined\")\n",
            "Nov 25 17:25:36 paul-serin discord_discord.desktop[5622]: [5622:1125/172536.571434:ERROR:object_proxy.cc(576)] Failed to call method: org.freedesktop.Secret.Service.ReadAlias: object_path= /org/freedesktop/secrets: org.freedesktop.DBus.Error.AccessDenied: An AppArmor policy prevents this sender from sending this message to this recipient; type=\"method_call\", sender=\":1.123\" (uid=1000 pid=5622 comm=\"/snap/discord/216/usr/share/discord/Discord --use-\" label=\"snap.discord.discord (enforce)\") interface=\"org.freedesktop.Secret.Service\" member=\"ReadAlias\" error name=\"(unset)\" requested_reply=\"0\" destination=\"org.freedesktop.secrets\" (uid=1000 pid=1967 comm=\"/usr/bin/gnome-keyring-daemon --daemonize --login \" label=\"unconfined\")\n",
            "Nov 25 17:25:39 paul-serin discord_discord.desktop[5886]: [5886:1125/172539.449943:ERROR:ffmpeg_common.cc(965)] Unsupported pixel format: -1\n",
            "Nov 25 17:26:33 paul-serin discord_discord.desktop[5622]: [5622:1125/172633.190294:ERROR:atom_cache.cc(230)] Add chromium/from-privileged to kAtomsToCache\n",
            "Nov 25 17:26:39 paul-serin ovpn-cytech.students[1358]: WARNING: Your certificate has expired!\n",
            "Nov 25 17:26:50 paul-serin discord_discord.desktop[5622]: 17:26:50.279 › [UploaderBase.tsx] _handleError: undefined ({\"type\":\"ERROR_SOURCE_UNKNOWN\",\"msg\":\"Error: File upload9 failed to upload\"}) for Uploader11\n",
            "Nov 25 17:26:50 paul-serin discord_discord.desktop[5622]: 17:26:50.673 › [UploaderBase.tsx] _handleError: undefined ({\"type\":\"ERROR_SOURCE_UNKNOWN\",\"msg\":\"Error: Unhandled error. (undefined)\"}) for Uploader11\n",
            "Nov 25 17:27:01 paul-serin gnome-shell[2515]: [2509:2533:1125/172701.160397:ERROR:cert_verify_proc_builtin.cc(1063)] CertVerifyProcBuiltin for arel.cy-tech.fr failed:\n",
            "Nov 25 17:27:01 paul-serin gnome-shell[2515]: ERROR: Time is after notAfter\n",
            "Nov 25 17:27:01 paul-serin gnome-shell[2515]: [2571:2578:1125/172701.160792:ERROR:ssl_client_socket_impl.cc(882)] handshake failed; returned -1, SSL error code 1, net_error -201\n",
            "Nov 25 17:27:31 paul-serin discord_discord.desktop[5622]: 17:27:31.012 › [UploaderBase.tsx] _handleError: undefined ({\"type\":\"ERROR_SOURCE_UNKNOWN\",\"msg\":\"Error: File upload12 failed to upload\"}) for Uploader14\n",
            "Nov 25 17:27:31 paul-serin discord_discord.desktop[5622]: 17:27:31.352 › [UploaderBase.tsx] _handleError: undefined ({\"type\":\"ERROR_SOURCE_UNKNOWN\",\"msg\":\"Error: Unhandled error. (undefined)\"}) for Uploader14\n",
            "Nov 25 17:27:54 paul-serin ovpn-cytech.students[1358]: WARNING: Your certificate has expired!\n",
            "Nov 25 17:28:11 paul-serin gnome-shell[2515]: [2509:2537:1125/172811.094616:ERROR:registration_request.cc(291)] Registration response error message: DEPRECATED_ENDPOINT\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Step 1: Assuming a SparkSession is already active\n",
        "# If not, uncomment the line below to initialize it\n",
        "spark = SparkSession.builder.appName(\"Inspect Log File\").getOrCreate()\n",
        "\n",
        "# Step 2: Load the syslog file\n",
        "log_file_path = \"/content/syslog\"  # Replace with the uploaded file path\n",
        "rdd = spark.sparkContext.textFile(log_file_path)\n",
        "\n",
        "# Step 3: Filter lines containing \"WARNING\" or \"ERROR\"\n",
        "bad_lines = rdd.filter(lambda line: \"WARNING\" in line or \"ERROR\" in line)\n",
        "\n",
        "# Step 4: Collect and display the bad lines\n",
        "bad_lines_collected = bad_lines.collect()\n",
        "print(\"Bad lines (WARNING and ERROR messages):\")\n",
        "for line in bad_lines_collected:\n",
        "    print(line)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qCMfcR1T4bHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataframe approach"
      ],
      "metadata": {
        "id": "dRBstjBoKYNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, when, lit\n",
        "\n",
        "# Step 1: Load the syslog file into a DataFrame\n",
        "df_logs = spark.read.text(log_file_path).withColumnRenamed(\"value\", \"line\")\n",
        "\n",
        "# Step 2: Add a column to classify lines as \"bad\" or \"good\"\n",
        "# A \"bad\" line contains \"WARNING\" or \"ERROR\", otherwise it is \"good\"\n",
        "df_logs = df_logs.withColumn(\n",
        "    \"is_bad\",\n",
        "    when((col(\"line\").contains(\"WARNING\")) | (col(\"line\").contains(\"ERROR\")), lit(1)).otherwise(lit(0))\n",
        ")\n",
        "\n",
        "# Step 3: Count the number of bad and good lines\n",
        "bad_lines_count = df_logs.filter(col(\"is_bad\") == 1).count()\n",
        "good_lines_count = df_logs.filter(col(\"is_bad\") == 0).count()\n",
        "\n",
        "# Step 4: Show results\n",
        "print(f\"Number of bad lines (WARNING or ERROR): {bad_lines_count}\")\n",
        "print(f\"Number of good lines: {good_lines_count}\")\n"
      ],
      "metadata": {
        "id": "S7OoWtMlKTls",
        "outputId": "2327248e-55f7-4df2-e3e3-fb33f50ba646",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of bad lines (WARNING or ERROR): 39\n",
            "Number of good lines: 10644\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}